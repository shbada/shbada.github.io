<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>shbada on TIL</title>
    <link>https://example.com/</link>
    <description>Recent content in shbada on TIL</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <atom:link href="https://example.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/044_runnable_callable/</link>
      <pubDate>Wed, 14 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/044_runnable_callable/</guid>
      <description>강의 메모 - Runnable and Callable # 개요 # Runnable 과 Callable 은 모두 별도의 스레드에서 실행할 수 있는 작업을 나타내는 데 사용되는 인터페이스이다 두 인터페이스 사이에는 몇 가지 중요한 차이점이 있다 # Runnable # class MyRunnable implements Runnable { public void run() { // 결과를 리턴 하거나 예외를 던질 수 없다 System.out.println(&amp;#34;Hello, world!&amp;#34;); } } Callable # class MyCallable implements Callable&amp;lt;Integer&amp;gt; { public Integer call() throws Exception { // 결과를 리턴 하거나 예외를 던질 수 있다 return 10; } } Callable &amp;amp; Future # Future을 우선 리턴하고 Callable의 call() 로직이 완료되면 결과가 들어온다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/system_design/003_system_design_interview/</link>
      <pubDate>Wed, 14 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/system_design/003_system_design_interview/</guid>
      <description>개발 책 읽기 : 가상 면접 사례로 배우는 대규모 시스템 설계 기초 1 # 3장. 시스템 설계 면접 공략법 # 시스템 설계 면접 # 두 명의 동료가 모호한 문제를 풀기 위해 협력하여 그 해결책을 찾아내는 과정에 대한 시뮬레이션 정해진 결말도 없고, 정답도 없다. 최종적으로 도출된 설계안은 설계 과정에 비하면 그다지 중요하지 않다.&#xA;면접관의 일차적 목표 : 능력 평가 # 면접관이 시스템 설계 면접에서 찾고자 하는 것은?&#xA;시스템 설계 면접이 잘 진행되면, 지원자가 협력에 적합한 사람인지?</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/042_threadpool/</link>
      <pubDate>Tue, 13 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/042_threadpool/</guid>
      <description>강의 메모 - 스레드 풀 이해와 구현 # 개요 # 스레드 풀 (Thread Pool) 은 다수의 스레드를 미리 생성하고 관리하여 작업을 효율적으로 처리하는 디자인 패턴이다 자바에서는 스레드 풀을 사용할 수 있는 Executor 프레임워크를 제공하고 있다 스레드 풀은 왜 필요한가 # 스레드 풀을 구현할 때 필요한 핵심 요소는 무엇인가 # 스레드 풀 구조 # 작업을 스레드 풀에 등록하면 스레드 풀은 큐에 작업을 저장한다 미리 생성된 스레드는 큐로부터 작업을 하나씩 가져가고 작업을 진행한다 작업을 완료하면 다음 작업을 할당받기 위해 시도한다 스레드가 할당 받을 작업이 없으면 요청이 들어올 때 까지 계속 대기한다 (wait) 할당 받을 작업이 올때까지 스레드가 모두 작업 중이고 큐에 작업이 존재할 경우 스레드를 추가 생성한다 가용할 수 있는 최대 스레드 개수만큼 생성 가능하기 때문에 추가 생성할 수 있음 일반적으로 스레드 생성 개수는 기본 개수와 최대 개수로 제한을 둔다 만약 Queue에 계속해서 작업이 들어오는데 Thread가 모두 working 중이면 Queue에 작업이 계속 쌓이게되어 쓰레드 풀이 예외를 발생시킬 수 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/043_executor/</link>
      <pubDate>Tue, 13 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/043_executor/</guid>
      <description>강의 메모 - Executor # 개요 # 자바 Executor Framework 는 자바의 java.util.concurrent 패키지에 포함된 스레드 관리와 병렬 처리를 위한 고급 기능들을 제공하는 포괄적인 라이브러리이다 Executor Framework 는 복잡한 스레드 생성, 관리, 동기화 등의 작업을 단순화하고 성능을 향상시키기 위한 다양한 클래스와 인터페이스를 제공하고 있다 Executor Framework # Executor # Executor Framework 의 핵심 인터페이스로서 단일 메서드 execute(Runnable command)를 정의하고 있으며 작업을 제출하면 Executor 구현체가 적절한 스레드를 생성하고 작업을 실행한다 ExecutorService # Executor 의 확장 버전으로서 작업의 제출과 스레드 풀의 종료를 관리하기 위한 메서드들을 추가로 제공한다 ScheduledExecutorService # ExecutorService 의 확장으로 특정 시간 또는 주기적으로 작업을 실행할 수 있도록 스케줄링하는 메서드들을 제공한다 Executor 구현체 # Executor 의 구현체로는 ThreadPoolExecutor,ScheduledThreadPoolExecutor 등이 있다 이들은 스레드 풀의 생성, 관리, 작업 큐, 스레드 생성 및 삭제 정책 등을 다양한 설정으로 제어할 수 있는 강력한 도구이다 Executor # 제출(Submit)된 Runnable 작업을 실행(Execute) 하는 객체 Executor 인터페이스는 각 작업의 실행(실행방법, 스레드 사용, 스케줄링 등의 세부 사항) 과 작업의 제출을 분리하는 방법을 제공한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/038_cas_algorithm/</link>
      <pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/038_cas_algorithm/</guid>
      <description>강의 메모 - CAS (Compare and Swap) 이해와 활용 - 1,2 # 개요 # CAS(Compare and Swap, 비교 후 치환) 는 멀티 스레드 환경에서 스레드 간의 경쟁 조건을 방지하고 락을 사용하지 않고도 공유 변수의 값을 원자적으로 변경하는 방법을 제공한다 CAS 는 CPU 캐시와 메인메모리의 두 값을 비교하고 그 값이 동일할 경우 새로운 값으로 교체하는 동기화 연산으로 여러 스레드가 공유하는 메모리 영역을 보호하는 데 사용된다 CAS 는 락 기반의 동기화보다 경량화되어 있으며 락을 사용하지 않기 때문에 대기하지 않는 넌블록킹 실행이 가능하고 경쟁 조건과 데드락을 피할 수 있다 CAS는 조건에 따라 실패하고 다시 시도해야 할 수 있기 때문에 동시적으로 접근하는 요청의 수가 많은 경쟁 조건일 경우 효율성이 저하될 수 있다 CAS는 주로 하드웨어 수준(CPU) 에서 지원되는 연산이며 Java에서는 java.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/039_atomic/</link>
      <pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/039_atomic/</guid>
      <description>강의 메모 - Atomic Variables - 단일연산변수 - 1,2 # 개요 # 단일연산변수는 락을 사용하지 않고도 여러 스레드 간에 안전하게 값을 공유하고 동기화하는 데 사용되며 기본적으로 volatile 의 속성을 가지고 있다 단일연산변수는 원자적인(read-modify-write) 연산을 지원하여 내부적으로 Compare and Swap (CAS) 연산을 사용하여 데이터의 일관성과 안정성을 유지한다 단일연산변수는 간단한 연산의 경우 락을 사용하는 것보다 월등히 빠른 성능을 보여 주지만 연산이 복잡거나 시간이 오래 걸리는 작업은 락을 사용하는 것보다 오버헤드가 커질 수 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/040_countDownLatch/</link>
      <pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/040_countDownLatch/</guid>
      <description>강의 메모 - CountDownLatch # 개요 # 하나 이상의 스레드가 다른 스레드에서 수행되는 일련의 작업이 완료될 때까지 기다릴 수 있게 해주는 동기화 보조 도구이다 CountDownLatch는 주어진 카운트로 초기화되고 await 메서드는 현재 카운트가 countDown 메서드의 호출로 인해 0이 될 때까지 블록되며 그 이후에 모든 대기 중인 스레드가 해제되고 await() 이후 처리가 이루어진다 CountDownLatch 은 일회성으로 처리된다. 즉 카운트를 재 설정할 수 없다( 카운트를 재설정하는 버전이 필요한 경우 CyclicBarrier 를 사용한다) 한 스레드가 여러 번 countDown() 을 호출해도 된다 사용 용도 # 여러 개의 스레드가 병렬로 실행되는 경우 특정 작업이 시작되거나 완료될 때까지 다른 스레드들이 기다리도록 할 수 있다 여러 스레드가 초기화 작업을 마칠 때까지 기다렸다가 모든 스레드가 완료되면 마무리 작업을 수행할 수 있습니다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/041_cyclicBarrier/</link>
      <pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/041_cyclicBarrier/</guid>
      <description>강의 메모 - CyclicBarrier # 개요 # CyclicBarrier 는 공통된 장벽 지점에 도달할 때까지 일련의 스레드가 서로 기다리도록 하는 동기화 보조 도구이다 각 스레드끼리 cycleBarrier을 공유하고 각각 쓰레드에서 await()을 호출해야한다. countDownLatch는 작업 기준이라면, CyclicBarrier는 쓰레드 기준 CyclicBarrier 는 대기 중인 스레드가 해제된 후에 재 사용할 수 있기 때문에 순환 장벽이라고 부른다 CyclicBarrier는 옵션으로 Runnable 명령을 지원하는데 이 명령은 마지막 스레드가 도착한 후에 각 장벽 지점마다 한 번씩 실행되는 장벽액션(barrierAction) 역할을 수행한다 이 Runnable 은 스레드가 장벽 이후 실행을 계속하기 전에 공유 상태를 업데이트하는 데 유용하다 각 하나의 쓰레드가 await()을 호출해야함 각 쓰레드가 await()을 호출하게 되면 -1씩 되어 0이 되는 시점이 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/system_design/001_system_expansion/</link>
      <pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/system_design/001_system_expansion/</guid>
      <description>개발 책 읽기 : 가상 면접 사례로 배우는 대규모 시스템 설계 기초 1 # 1장. 사용자 수에 따른 규모 확장성 # 개요 # 1명의 사용자를 지원하는 시스템 -&amp;gt; 몇백만 사용자를 지원하는 시스템으로 설계 확장&#xA;단일 서버 # 웹, 앱, 데이터베이스, 캐시 등이 전부 서버 한 대에서 실행된다.&#xA;사용자는 도메인 이름(api.mysite.com)을 이용하여 웹사이트에 접속한다. 위 접속을 위해서는 도메인 이름을 도메인 이름 서비스(Domain Name Service, DNS)에 질의하여 IP 주소로 변환하는 과정이 필요하다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/system_design/002_system_size_estimation/</link>
      <pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/system_design/002_system_size_estimation/</guid>
      <description>개발 책 읽기 : 가상 면접 사례로 배우는 대규모 시스템 설계 기초 1 # 2장. 개략적인 규모 추정 # 개요 # 시스템 용량이나 성능 요구사항을 개략적으로 추정&#xA;개략적인 규모 추정(back-of-the-enveope estimation) : 보편적으로 통용되는 성능 수치상에서 사고 실험을 행하여 추정치를 계산하는 행위 어떤 설계가 요구사항에 부합할 것인지 보기 위한 것 효과적인 개략적 규모 추정을 위해서는 규모 확장성을 표현하는 데 필요한 기본기에 능숙해야 한다. 2의 제곱수 # 분산 시스템에서 다루는 데이터 양은 엄청나게 커질 수 있으나 그 계산법은 기본을 크게 벗어나지 않는다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/036_reentrantReadWriteLock/</link>
      <pubDate>Wed, 07 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/036_reentrantReadWriteLock/</guid>
      <description>강의 메모 - ReentrantLock # 개요 # ReadWriteLock 은 읽기 작업과 쓰기 작업을 위해 연관된 두 개의 락(읽기 락, 쓰기 락)을 유지하는 인터페이스이다 일반적으로 락은 데이터를 조작하는 하나의 스레드의 임계영역을 보호하는 장치이며 데이터를 읽는 작업만 실행되는 영역은 여러 스레드가 동시에 접근해도 동시성 문제가 발생하지 않는다 읽기 작업이 많고 쓰기 작업이 적은 영역을 효율적으로 처리하기 위해 다수의 읽기와 하나의 쓰기를 읽기락과 쓰기락으로 구분해서 락을 운용하는 것이 필요하다 특징 # 성능 개선</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/037_condition/</link>
      <pubDate>Wed, 07 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/037_condition/</guid>
      <description>강의 메모 - Condition # 개요 # Condition 은 조건 변수 또는 조건 큐로 알려진 객체로서 Lock 과 결합하여 객체 당 여러 개의 Wait Queue 을 가지는 효과를 제공한다 Lock 이 synchronized 메서드와 문장의 사용을 대체하는 것처럼 Condition은 Object 모니터 메서드 (wait, notify and notifyAll) 의 사용을 대체하며 Lock 에 바인딩된다 Condition 은 한 스레드가 다른 스레드로부터 어떤 상태 조건이 참이 될 수 있다는 통지를 받을 때까지 실행을 중단하도록 하는 수단을 제공한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/springbatch/004_JobParameter/</link>
      <pubDate>Sun, 04 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/springbatch/004_JobParameter/</guid>
      <description>강의메모 # 스프링 배치 도메인 이해 - JobParameter # 기본 개념 # Job을 실행할 때 함께 포함되어 사용되는 파라미터를 가진 도메인 객체 하나의 Job에 존재할 수 있는 여러개의 JobInstance를 구분하기 위한 용도 JobParameters와 JobInstance는 1:1 관계 생성 및 바인딩 # 어플리케이션 실행 시 주입&#xA;Java -jar LogBatch.jar requestDate=20210101 코드로 생성&#xA;JobParameterBuilder @Component public class JobParameterTest implements ApplicationRunner { @Autowired JobLauncher jobLauncher; @Autowired Job job; @Override public void run(ApplicationArguments args) throws Exception { JobParameters jobParameters = new JobParametersBuilder().</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/springbatch/005_JobExecution/</link>
      <pubDate>Sun, 04 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/springbatch/005_JobExecution/</guid>
      <description>강의메모 # 스프링 배치 도메인 이해 - JobExecution # 기본 개념 # JobIstance 에 대한 한번의 시도를 의미하는 객체로서 Job 실행 중에 발생한 정보들을 저장하고 있는 객체 시작시간, 종료시간 ,상태(시작됨,완료,실패),종료상태의 속성을 가짐 JobIstance 과의 관계 JobExecution은 &amp;lsquo;FAILED&amp;rsquo; 또는 &amp;lsquo;COMPLETED‘ 등의 Job의 실행 결과 상태를 가지고 있음 JobExecution 의 실행 상태 결과가 &amp;lsquo;COMPLETED’일 경우 JobInstance 실행이 완료된 것으로 간주해서 재실행이 불가함 JobExecution 의 실행 상태 결과가 &amp;lsquo;FAILED’일 경우 JobInstance 실행이 완료되지 않은 것으로 간주해서 재실행이 가능함 JobParameter가 동일한 값으로 Job 을 실행할지라도 JobInstance를 계속 실행할 수 있음 JobExecution 의 실행 상태 결과가 &amp;lsquo;COMPLETED’ 될 때까지 하나의 JobInstance 내에서 여러 번의 시도가 생길 수 있음 JobInstance와 JobExcecution 관계 # https://devfunny.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/035_reentrantLock/</link>
      <pubDate>Tue, 30 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/035_reentrantLock/</guid>
      <description>강의 메모 - ReentrantLock # 개요 # ReentrantLock 은 락 획득 과정에서 스레드가 대기하거나 차단하지 않는 API 를 지원하여 유연한 코드 구현이 가능하다 tryLock() 락을 획득한 경우와 획득하지 못한 경우를 별도로 처리해야하는 상황에서 사용 finally에서 lock 해제 필수 lockInterruptibly() 인터럽트의 명령을 받으면 catch 문 수행 ReentrantLock # ReentrantLock() // ReentrantLock(false)를 사용하는 것과 동일하며 내부적으로 NonfairSync 클래스 객체인 불공정성 락을 생성한다 ReentrantLock(boolean fair) //주어진 공정성 정책으로 인스턴스를 생성한다. 공정성 락을 사용해야 하는 경우 fair 는 true 이며 내부적으로 FairSync 클래스 객체를 생성한다 // 현재 스레드가 이 락을 보유한 횟수를 반환하며이 락을 보유하지 않은 경우에는 0 을 반환한다 int getHoldCount() // 현재 스레드가 이 락을 보유하고 있는지 확인한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/008_topic_partition/</link>
      <pubDate>Mon, 29 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/008_topic_partition/</guid>
      <description>강의 메모 # 토픽과 파티션 # 토픽과 파티션 # 토픽은 반드시 1개 이상의 파티션을 가져야한다. 파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되는데, 이 데이터를 &amp;lsquo;레코드&amp;rsquo;라고 한다. 파티션에 있는 구조는 큐와 비슷 일반적인 큐는 데이터를 pop() 하면 삭제되는데, 카프카는 컨슈머가 데이터를 가져가더라도 데이터가 삭제되지않고 유지된다. 여러개의 컨슈머 그룹들이 토픽의 데이터를 여러번 가져갈 수 있다.&#xA;토픽 생성시 파티션이 배치되는 방법 # 파티션이 5개일 경우 그림과 같이 배치될 수 있다 0번 브로커부터 시작하여 round-robin 방식으로 리더 파티션들이 생성된다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/009_record/</link>
      <pubDate>Mon, 29 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/009_record/</guid>
      <description>강의 메모 # 레코드 # 레코드 # 레코드는 타임스탬프, 헤더, 메시지 키, 메시지 값, 오프셋으로 구성되어있다. 프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋이 지정되고, 옵션에 따라서 타임스탬프가 저장된다. 기본적으로 프로듀서는 오프셋을 가지고있지않고 레코드가 브로커에 저장될때만 오프셋이 있다. 브로커에 한번 적재된 레코드는 수정할 수 없다. 로그 리텐션 기간 또는 용량에 따라서만 삭제된다.&#xA;레코드 - 타임스탬프 # 스트림 프로세싱에서 활용하기 위한 시간을 저장하는 용도 기본값 : 프로듀서 레코드 생성 시간 (CreateTime) 또는 브로커 적재 시간(LogAppendTime)으로 설정할 수도 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/010_metadata/</link>
      <pubDate>Mon, 29 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/010_metadata/</guid>
      <description>강의 메모 # 클라이언트 메타데이터와 브로커 통신 # 클라이언트 메타데이터 # 카프카 클라이언트는 통신하고자 하는 리더 파티션의 위치를 알기 위해 데이터를 주고받기 전에 메타데이터를 브로커로부터 전달받는다. 다음과 같은 옵션으로 리프래쉬된다.&#xA;metadata.max.age.ms : 메타데이터를 강제로 리프래쉬하는 간격 (기본값: 5분) metadata.max.idle.ms : 프로듀서가 유휴상태일 경우 메타데이터를 캐시에 유지하는 기간 프로듀서가 특정 토픽으로 데이터를 보낸 이후 지정한 시간이 지나고나면 강제로 메타데이터를 리프래쉬 (기본값 5분) 리더 파티션이 어디에 위치하고있는지를 받게되는것! 클라이언트 메타데이터가 이슈가 발생한 경우 # 카프카 클라이언트는 반드시 리더 파티션과 통신해야한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/034_lock_ReentrantLock/</link>
      <pubDate>Mon, 29 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/034_lock_ReentrantLock/</guid>
      <description>강의 메모 - Lock &amp;amp; ReentrantLock - 1,2 # 개요 # Lock 구현은 synchronized 구문과 마찬가지로 상호배제와 가시성 기능을 가진 동기화 기법이며 synchronized 보다 더 확장된 락 작업을 제공한다&#xA;Lock 구현은 락을 획득 시 블록되지 않는 비 차단 시도(tryLock()), 인터럽트가 가능한 방식으로 락을 획득하는 시도(lockInterruptibly) 및 시간 제한을 둔 방식으로 락을 획득하는 시도(tryLock(long, TimeUnit))와 같은 추가 기능을 제공한다&#xA;synchronized 사용은 락 획득과 락 해제가 블록 구조화된 방식으로 발생하도록 강제한다</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/032_volatile/</link>
      <pubDate>Sun, 28 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/032_volatile/</guid>
      <description>강의 메모 - volatile # 개요 # volatile 은 변수의 가시성과 연산의 순서를 제어하기 위해 사용하는 키워드로서 스레드 간의 데이터 일관성과 가시성을 보장하는 역할을 한다 가시성 보장 : 모든 쓰레드가 동일한 값을 보는것 CPU 캐시 메모리와 메인 메모리 # 현대 컴퓨터는 거의 대부분 2개 이상의 CPU가 장착되어 있으며 각 코어에는 레지스터와 캐시메모리가 존재한다 CPU 캐시 메모리는 CPU 레지스터와 메인 메모리 사이에서 데이터 흐름을 최적화하고 성능을 향상시키기 위해 사용되는 고속 메모리이다 CPU 는 값을 읽어올 때 우선 캐시에 해당 값이 있는지 확인하고 없는 경우에만 메인 메모리에서 읽어오는 특성을 가진다 CPU 가 데이터 처리를 위해 메인 메모리로 접근 할 때 다음과 같은 순서로 진행한다</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/033_deadlock/</link>
      <pubDate>Sun, 28 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/033_deadlock/</guid>
      <description>강의 메모 - Deadlock - 교착상태 - 1,2 # 개요 # DeadLock(교착상태) 이란 프로세스나 스레드들이 서로가 소유하고 있는 자원을 기다리며 무한히 대기하고 있는 상태를 말한다 교착상태에서는 아무런 진전도 이루어지지 않아 작업이 진행되지 않는 문제가 발생한다 DeadLock 은 동일한 환경과 코드에서 발생할 수도 있고 발생하지 않을 수도 있다 완전한 해결은 없고, &amp;lsquo;예방&amp;rsquo;과 &amp;lsquo;최소화&amp;rsquo;하는 느낌 - 예측이 어려운 상황 데드락 발생 조건 # 데드락은 다음의 네 가지 필요 조건을 동시에 만족할 때 발생한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/etc/005_rabbit_mq/</link>
      <pubDate>Sat, 27 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/etc/005_rabbit_mq/</guid>
      <description>기술 블로그 정리 # RabbitMQ란? # RabbitMQ란? # AMQP를 따르는 오픈소스 메시지 브로커 메시지를 많은 사용자에게 전달하거나, 요청에 대한 처리 시간이 길 때, 해당 요청을 다른 API에게 위임하고 빠른 응답을 할때 많이 사용한다. AMQP # Advanced Message Queueing Protocol MQ의 오픈소스에 기반한 표준 프로토콜을 의미한다.&#xA;RabbitMQ 개념 # 1. Producer # 메시지를 생성하고 발송하는 주체 이 메시지가 Queue에 저장된다. Producer는 Queue에 직접 접근하지 않고, 항상 Exchange를 통해 접근하게 된다. 2.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/006_replication/</link>
      <pubDate>Sat, 27 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/006_replication/</guid>
      <description>강의 메모 # 브로커의 복제(Replication) # 브로커의 역할 - 복제(Replication) # 데이터 복제 : 클러스터로 묶인 브로커 중 일부에 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함이다. 토픽을 생성할때 파티션의 복제 개수(replication factor) 같이 설정 - default는 브로커에 설정된 옵션 값으로 설정&#xA;복제 개수의 최솟값은 1(복제 없음) 최댓값은 브로커 개수만큼 설정하여 사용 가능 복제된 파티션의 구성 : 리더(leader), 팔로워(follower)&#xA;리더 : 프로듀서, 컨슈머와 직접 통신하는 파티션 팔로워 : 리더의 데이터가 추가되면 복제해가는 역할 복제 과정 : 팔로워 파티션들은 리더 파티션의 오프셋을 확인하여 현재 자신이 가지고있는 오프셋과 차이가 나는 경우 리더 파티션으로부터 데이터를 가져와서 자신의 파티션에 저장한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/007_isr/</link>
      <pubDate>Sat, 27 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/007_isr/</guid>
      <description>강의 메모 # ISR (In-Sync-Replicas) # ISR (In-Sync-Replicas) # 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태를 뜻한다. 리더 파티션의 오프셋이 0~3까지 있을때 팔로워 파티션도 0~3이 있다. (동기화 완료 - 리더 파티션의 모든 데이터가 팔로워 파티션에 복제가 완료되었다 라는 뜻)&#xA;unclean.leader.election.enable # 모두 복제되지 않은 상황이고, 이렇게 싱크가 되지 않은 팔로워 파티션이 리더 파티션으로 선출되면 데이터가 유실될 수 있다. 유실이 발생하더라도 서비스를 중단하지 않고 지속적으로 토픽을 사용하고 싶으면 ISR이 아닌 팔로워 파티션을 리더로 선출하도록 설정할 수 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/031_wait_notify/</link>
      <pubDate>Sat, 27 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/031_wait_notify/</guid>
      <description>강의 메모 - 스레드 간 협력 - wait() &amp;amp; notify() # 개요 # wait(), notify(), notifyAll() 은 모니터 객체의 조건변수와 함께 사용해서 동기화를 구현할 수 있는 동기화 메커니즘이라 할 수 있다. wait(), notify(), notifyAll() 은 뮤텍스(상호배제) 동기화 기법으로 충족되지 않는 동기화 문제를 해결할 수 있는 협력에 의한 동기화 장치이다 wait(), notify(), notifyAll() 은 반드시 synchronized 블록 안에서만 사용해야 하며 이는 스레드가 모니터 락을 확보한 상태에서 이 API 들이 작동한다는 것을 의미한다 모니터 락 안에서 사용해야한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/springbatch/002_Job/</link>
      <pubDate>Sat, 27 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/springbatch/002_Job/</guid>
      <description>강의메모 # 스프링 배치 도메인 이해 - Job # 기본 개념 # 배치 계층 구조에서 가장 상위에 있는 개념 하나의 배치작업 자체를 의미함 ex) API 서버의 접속 로그 데이터를 통계 서버로 옮기는 배치 Job 자체를 의미 Job Configuration 을 통해 생성되는 객체 단위로서 배치작업을 어떻게 구성하고 실행할 것인지 전체적으로 설정하고 명세해 놓은 객체 배치 Job 을 구성하기 위한 최상위 인터페이스이며 스프링 배치가 기본 구현체를 제공한다 여러 Step 을 포함하고 있는 컨테이너로서 반드시 한개 이상의 Step으로 구성해야 함 기본 구현체 # SimpleJob 순차적으로 Step 을 실행시키는 Job 모든 Job에서 유용하게 사용할 수 있는 표준 기능을 갖고 있음 FlowJob 특정한 조건과 흐름에 따라 Step 을 구성하여 실행시키는 Job Flow 객체를 실행시켜서 작업을 진행함 References https://www.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/springbatch/003_JobInstance/</link>
      <pubDate>Sat, 27 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/springbatch/003_JobInstance/</guid>
      <description>강의메모 # 스프링 배치 도메인 이해 - JobInstance # 기본 개념 # Job 이 실행될 때 생성되는 Job의 논리적 실행 단위 객체 고유하게 식별 가능한 작업 실행을 나타냄 Job 의 설정과 구성은 동일하지만 Job 이 실행되는 시점에 처리하는 내용은 다르기 때문에 Job 의 실행을 구분해야 함 ex) 하루에 한 번 씩 배치 Job이 실행된다면 매일 실행되는 각각의 Job 을 JobInstance 로 표현 JobInstance 생성 및 실행 처음 시작하는 Job + JobParameter 일 경우 새로운 JobInstance 생성 이전과 동일한 Job + JobParameter 으로 실행 할 경우 이미 존재하는 JobInstance 리턴 내부적으로 JobName + jobKey (jobParametes 의 해시값) 를 가지고 JobInstance 객체를 얻음 Job 과는 1:M 관계 BATCH_JOB_INSTANCE 테이블과 매핑 # JOB_NAME (Job) 과 JOB_KEY (JobParameter 해시값) 가 동일한 데이터는 중복해서 저장할 수 없음</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/030_synchronized_etc/</link>
      <pubDate>Thu, 25 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/030_synchronized_etc/</guid>
      <description>강의 메모 - synchronized 특성 # 재진입성 # 모니터 내에서 이미 synchronized 영역에 들어간 스레드가 다시 같은 모니터 영역으로 들어갈 수 있는데, 이를 &amp;ldquo;모니터 재진입&amp;quot;이라고 한다 재진입 가능하다는 것은 락의 획득이 호출 단위가 아닌 스레드 단위로 일어난다는 것을 의미하며 이미 락을 획득한 스레드는 같은 락을 얻기 위해 대기할 필요 없이 synchronized 블록을 만났을 때 같은 락을 확보하고 진입한다 같은 모니터라면 대기/경쟁 없이 바로 진입 가능 (스레드 단위) 상속하게 되면 자식은 부모의 락과 동일한 락을 가지게 된다 자식 클래스에서 method() 실행됨 부모클래스의 method() 실행 서로 모니터가 동일하므로 재진입이 가능한것 동기화 된 메서드에서 다른 동기화 된 메서드를 호출하는 경우 이미 락(lock)을 가지고 있는 스레드가 같은 락을 확보하고 재진입 시 데드락이 발생하지 않고 정상적으로 진행할 수 있게 된다 가시성 # synchronized 는 가시성을 지원한다 가시성이란 한 스레드가 공유자원을 수정하거나 쓰기 작업을 했을 때 다른 스레드가 수정한 내용이 보이는 것을 말한다 CPU 특성상 cache memory를 가진다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/029_method_synchronized/</link>
      <pubDate>Mon, 22 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/029_method_synchronized/</guid>
      <description>강의 메모 - synchronized 메서드 동기화 # 인스턴스 메서드 동기화 (synchronized method) # 인스턴스 단위로 모니터가 동작하며 동일한 인스턴스 안에서 synchronized 가 적용된 곳은 하나의 락을 공유한다 인스턴스가 여러개일 경우 인스턴스별로 모니터 객체를 가지므로 스레드는 모니터 별로 락을 획득해서 동기화 영역에 진입하고 빠져 나올 때 락을 해제 할 수 있다 MyClass 내부적으로 가지고있는 객체 타입 : this (=모니터) 위 두 메서드의 모니터가 동일하다. 정적 메서드 동기화 (static synchronized method) # 클래스 단위로 모니터가 동작하며 synchronized 가 적용된 곳은 하나의 락을 공유한다 인스턴스와는 별개의 모니터를 가지고 임계 영역을 동기화 하기 때문에 인스턴스 단위로 메서드를 호출할지라도 락은 클래스 단위로 스레드간 공유된다 클래스는 메모리에 오직 하나만 존재하므로 하나의 모니터를 공유해서 동기화 하고자 할 때 사용 할 수 있다 정적메서드이기 때문에 클래스 타입으로 주어짐 -&amp;gt; MyCalss = monitor 인스턴스 메서드 동기화 (synchronized method) + 정적 메서드 동기화 (static synchronized method) # synchronized method 와 static synchronized method 가 혼용되었을 경우는 각 모니터별로 동기화를 진행한다 모니터가 섞여 있기 때문에 동기화가 의도한대로 정확하게 동작하는지 주의가 필요하다 위 1, 2 메서드의 모니터는 같다 위 3,4 메서드의 모니터는 같다 References 강의 : https://www.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/004_kafka_broker/</link>
      <pubDate>Sun, 21 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/004_kafka_broker/</guid>
      <description>강의 메모 # 카프카 브로커, 클러스터, 주키퍼 # 주키퍼 # 카프카 클러스터를 운영하기 위해 반드시 필요한 애플리케이션 카프카 2.0 버전 까지는 반드시 필요했지만 카프카 3.0부터는 주키퍼가 없더라도 운영됨 아직까지는 주키퍼를 완벽하게 대체하지 못하므로 주키퍼가 있는 카프카 클러스터 운영 기업이 많음&#xA;1개의 브로커는 하나의 서버나 인스턴스에서 동작 브로커 3개가 있는 모습&#xA;브로커 # 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션 하나의 서버에는 하나의 카프카 브로커 프로세스가 실행됨 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영한다 카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산 저장하고 복제하는 역할을 수행한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/005_broker_log_segment/</link>
      <pubDate>Sun, 21 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/005_broker_log_segment/</guid>
      <description>강의 메모 # 로그와 세그먼트 # log.segment.bytes : 바이트 단위의 최대 세그먼트 크기 지정 (기본 값은 1GB)&#xA;log.roll.ms(hours) : 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기 (기본값은 7일)&#xA;프로듀서가 데이터를 전송하면 active 되어있는 .log 파일에 offset 22번으로 들어간다. (FIFO)&#xA;가장 최초의 offset 번호가 파일 이름이 된다&#xA;가장 마지막 세그먼트 파일을 active segment라고 한다.&#xA;브로커의 삭제 대상에서 포함되지 않는다. retention 옵션에 ㄸ라 삭제 대상으로 지정된다. 세그먼트와 삭제 주기 (cleanup.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/003_transactional_outbox_pattern/</link>
      <pubDate>Sat, 20 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/003_transactional_outbox_pattern/</guid>
      <description>기술 블로그 정리 # Transactional Outbox 패턴이 등장하게된 상황 # Event Driven Architecture &amp;gt; 메시지 발행의 신뢰성 보장 패턴 Event driven ARchitecture : Message Broker를 이용해 다양한 메시지(이벤트)를 publish(발행) 하고, 그에 연관된 작업을 비동기적으로 처리하여 시스템을 통합 DB 트랜잭션을 실행한 뒤, 연관 메시지를 Message Broker에 publish 하게 되는데, 메시지 publish가 반드시 완료되어야하는 경우가 있다. 예시) 리디 주문 기능; 주문이 발생하면 사용한 캐시&amp;amp;포인트 금액을 차감하고 상품을 지급하며 주문 완료로 상태를 바꾸는 DB 트랜잭션이 발생 -&amp;gt; Message Broker에 주문 완료 메시지를 publish 이 경우, DB와 Message Broker의 트랜잭션 원자성 보장이 어렵다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/027_spin_lock/</link>
      <pubDate>Sat, 20 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/027_spin_lock/</guid>
      <description>강의 메모 - SpinLock &amp;amp; Busy Waiting # 개요 # 스핀락(SpinLock)은 뮤텍스나 세마포어와 같은 동기화 기법의 일종으로, 기다리지 않고 스레드가 임계영역을 사용할 수 있을 때까지 계속 반복하여 검사하는 동기화 메커니즘이다 작동방식 # 스레드가 공유 자원에 접근하려고 할 때, 먼저 스핀락을 시도한다 test_and_set() 함수가 이전 락 값인 0 을 반환하면 아직 락이 잠기지 않았다는 것을 의미하며 while 루프를 빠져 나온다 스레드는 스핀락을 얻고 해당 자원을 사용한다 그러나 이전 락 값이 1이면 이미 다른 스레드에 의해 잠긴 것을 의미하며 스핀락을 얻을 때까지 계속해서 반복적으로 검사를 수행한다 스레드가 자원 사용이 끝나면 lock 을 0 으로 변경해서 스핀락을 해제한다 Busy Waiting (바쁜 대기) # Busy waiting은 스레드가 어떤 조건이 만족될 때까지 계속해서 반복적으로 검사하는 것을 말한다 스레드가 특정 조건을 기다리는 동안 아무런 유용한 작업을 수행하지 않고, 무한 반복 루프를 돌며 CPU 자원을 계속 사용하는 것을 의미한다 스핀락은 이러한 busy waiting을 사용하는 동기화 기법 중 하나이다 스핀락 자바 구현 # 임계영역을 수행하고 unlock() 호출 스핀락의 장점, 단점 # 장점</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/028_synchronized_basic/</link>
      <pubDate>Sat, 20 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/028_synchronized_basic/</guid>
      <description>강의 메모 - synchronized 기본 # 개요 # 자바는 단일 연산 특성을 보장하기 위해 synchronized 키워드를 제공하고 있으며 synchronized 구문을 통해 모니터 영역을 동기화 할수 있다 synchronized 는 명시적으로 락을 구현하는 것이 아닌 자바에 내장된 락으로서 이를 암묵적인 락(Intrinsic Lock) 혹은 모니터락 (Monitor Lock) 이라고 한다 자바에 내장된 락 (암묵적인 락, 모니터락) synchronized 은 동일한 모니터를 가진 객체에 대해 오직 하나의 스레드만 임계영역에 접근할 수 있도록 보장하며 모니터의 조건 변수를 통해 스레드간 협력으로 동기화를 보장해 준다 synchronized 가 적용된 한 개의 메서드만 호출해도 같은 모니터의 모든 synchronized 메서드까지 락에 잠기게 되어 락이 해제될 때 까지는 접근이 안되는 특징을 가지고 있다 앞에서 배운 &amp;lsquo;모니터&amp;rsquo;를 synchronized 키워드에 넣었으므로 모니터 장점을 가지고있음 락은 스레드가 synchronized 블록에 들어가기 전에 자동 확보되며 정상적이든 비정상적이든 예외가 발생해서든 해당 블록을 벗어날 때 자동으로 해제된다 lock은 자동 확보/자동 해제 synchronized 는 모니터 락을 사용하여 동기화 할 수 있는 4가지 방법을 제공한다 # method synchronized method static synchronized method block synchronized block static synchronized method 원리는 동일 세부적으로는 인스턴스냐, 클래스냐 (method, block 각각 안에서도 세부적으로 나누는 기준) A 메서드 안에 4가지(위 구분 4가지)를 정의했다고 해보자.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/026_monitor/</link>
      <pubDate>Fri, 19 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/026_monitor/</guid>
      <description>강의 메모 - Monitor - 모니터 -1,2 # 개요 # 자바가 동기화를 지원하기 위해 사용하는 메커니즘은 모니터(Monitor) 이며 뮤텍스나 세마포어보다 더 고수준의 동기화 기법이다 뮤텍스, 세마포어를 좀더 추상화한것 모든 자바 객체는 기본적으로 모니터를 가지며 여러 스레드가 객체의 임계 영역(critical section)에 진입하려고 할 때 JVM 은 모니터를 사용하여 스레드 간 동기화를 제공한다 자바의 모니터는 상호 배제(Mutual Exclusion) 및 협력(Cooperation)이라는 두 가지 동기화 기능을 제공하고 있으며 이를 위해 뮤텍스와 조건변수(Condition Variable)를 사용한다 상호배제 (Mutual Exclusion) # 객체가 가지고 있는 모니터 Lock 을 통해 여러 스레드가 동시에 공유 자원에 접근하는 것을 막아 데이터의 일관성과 안전성을 보장하는 메커니즘이다 JVM 은 &amp;lsquo;synchronized&amp;rsquo; 키워드를 이용하여 뮤텍스 동기화를 암묵적으로 처리해 주고 있으며 synchronized 는 메서드나 코드 블록에 적용할 수 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/etc/004_sonar_qube/</link>
      <pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/etc/004_sonar_qube/</guid>
      <description>기술 블로그 정리 # 코드 분석 도구 적용기 - 3편, SonarQube 적용하기 # SonarQube란? # 정적 코드 분석 도구 # 정적 프로그램 분석(static program analysis) : 실제 실행 없이 컴퓨터 소프트웨어를 분석하는 것 정적 분석은 코드의 모든 부분을 확인할 수 있지만, 실행 환경에서의 상태를 정확히 알 수 없기 때문에 실행할 때에만 알 수 있는 데이터가 필요한 경우 정확히 분석하기 어렵다. SonarQube # 20개 이상의 프로그래밍 언어에서 버그, 코드 스멜, 보안 취약점을 발견할 목적으로 정적 코드 분석으로 자동 리뷰를 수행하기 위한 지속적인 코드 품질 검사용 오픈 소스 플랫폼 소나소스(SonarSource)가 개발 소나큐브는 중복 코드, 코딩 표준, 유닛 테스트, 코드 커버리지, 코드 복잡도, 주석, 버그 및 보안 취약점의 보고서를 제공 정적 코드 분석 도구 중 하나로, 레퍼런스가 많고, Github 또는 Jenkins와의 연동을 통해 자동 정적 코드 분석을 구성할 수 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/002_kafka_intro/</link>
      <pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/002_kafka_intro/</guid>
      <description>강의 메모 # 아파치 카프카의 탄생과 기본 구조 # 카프카의 탄생&#xA;각각의 애플리케이션끼리 연결하여 데이터를 처리하는게 아닌, 한 곳에 모아 처리할 수 있도록 중앙집중화했다. 메시지 큐 구조를 그대로 살린 카프카 내부 구조 # 카프카 내부에 데이터가 저장되는 파티션의 동작은 FIFO(First In First Out) 방식의 큐 자료구조와 유사하다. 큐에 데이터를 보내는 것이 프로듀서 큐에서 데이터를 가져가는 것이 컨슈머 적재된 데이터를 하나하나 가져가더라도 파티션 내의 데이터는 삭제되지 않는다. 데이터를 읽는것 : 커밋 (데이터를 어디까지 읽었는지를 기록) 카프카가 데이터 파이프라인으로 적합한 4가지 이유 # 1.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/024_mutual_exclusion/</link>
      <pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/024_mutual_exclusion/</guid>
      <description>강의 메모 - Mutual Exclusion - 상호 배제 # 개요 # 뮤텍스(Mutual Exclusion) 또는 상호 배제는 공유 자원에 대한 경쟁 상태를 방지하고 동시성 제어를 위한 락 메커니즘이다 스레드가 임계영역에서 Mutex 객체의 플래그를 소유하고 있으면(락 획득) 다른 스레드가 액세스할 수 없으며 해당 임계영역에 액세스하려고 시도하는 모든 스레드는 차단되고 Mutex 객체 플래그가 해제된 경우(락 해제)에만 액세스할 수 있다 이 메커니즘은 Mutex 락을 가진 오직 한개의 스레드만이 임계영역에 진입할 수 있으며 락을 획득한 스레드만이 락을 해제 할 수 있다 결론 : 뮤텍스는 락과 락해제를 통해 자원을 보호하는 락체계 동기화 도구이다 Mutex 문제점 # 데드락(Deadlock)</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/025_semaphore/</link>
      <pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/025_semaphore/</guid>
      <description>강의 메모 - Semaphore - 세마포어 - 1,2 # 개요 # 세마포어는 공유 자원에 대한 접근을 제어하기 위해 사용되는 신호전달 메커니즘 동기화 도구이다 Mutex는 락을 획득한 쓰레드가 락을 해제 할 수 있음 세마포어 : 신호전달로, 쓰레드가 임계영역에 들어갈 수 있도록 락을 풀어주거나 하나가 아닌 여러 쓰레드가 락을 동시에 가질 수 있다. 세마포어는 정수형 변수 S 와 P(Proberen: try), V(Verhogen: increment)의 두 가지 원자적 함수로 구성된 신호전달 메커니즘 동기화 도구이다 P : 임계 영역을 사용하려는 스레드의 진입 여부를 결정하는 연산, Wait 연산이라고도 함 락을 획득하는것 V : 대기 중인 프로세스를 깨우는 신호(Wake-up)로 Signal 연산 락을 획득하고 연산한 이후, 락을 해제하는것 스레드가 임계영역에 진입하지 못할 경우 자발적으로 &amp;lsquo;대기(BLOCK)&amp;lsquo;상태에 들어가고 임계영역을 빠져나오는 스레드가 대기상태의 스레드를 실행대기상태로 깨워준다 자바에서는 java.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/020_single_multi_thread/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/020_single_multi_thread/</guid>
      <description>강의 메모 - 싱글스레드 &amp;amp; 멀티스레드 # 개요 # 프로세스는 오직 한개의 스레드로만 구성하는 싱글 스레드 프로세스와 하나 이상의 스레드로 구성하는 멀티 스레드 프로세스로 구분할 수 있다 작업 처리에 있어서 단일스레드와 멀티 스레드의 선택 기준은 어떤 방식이 자원을 더 효율적으로 사용하고 성능처리에 유리한가 하는 점이다 현대 CPU 는 대부분 멀티코어를 지원하기 때문에 병렬적 성능 및 동시적 자원 사용 관점에서는 싱글 스레드보다 멀티스레드 기반 프로그래밍이 유리한 점이 많다 싱글 스레드 혹은 아주 적은 스레드를 활용한 비동기 논블럭킹 프로그래밍은 많은 수의 멀티 스레드 기반 프로그래밍 보다 더 좋은 성능과 응답성을 보여줄 수 있다 단일스레드 # 장점 # 문맥교환이 없다 동기화 이슈가 없다 자원 비용이 적다 프로그래밍 난이도가 낮다 단점 # CPU 멀티코어 활용 못함　순차적 실행으로 응답성 및 전체 처리량이 낮다 I/O 처리 시 CPU 가 낭비된다　스레드에 오류가 발생하면 프로그램이 종료된다 멀티스레드 # 장점 # 동시성으로 사용자의 응답성 향상 CPU 멀티코어의 병렬성으로 성능 향상 CPU 낭비 없는 자원의 효율적인 사용　한 스레드 오류는 다른 스레드에 영향이 없다　단점 # 빈번한 문맥교환으로 성능이 저하 된다　스레드 간 동기화 이슈가 발생한다 스레드 생성 비용이 작지 않다 프로그래밍 난이도가 높다　멀티스레딩과 동시성 # CPU 의 동시적 작업 처리는 CPU 코어 개수보다 스레드의 개수가 많을 때 즉 , 멀티스레딩 환경에서 자원을 효율적으로 배분하고 사용하기 위해 설계된 방식이다 같은 프로그램 안에서 실행되는 여러 스레드가 읽기 및 쓰기 작업을 같은 메모리 영역에서 동시에 실행할 경우 동시성 문제가 대두된다 동시성 문제라 함은 하나의 스레드가 어떤 메모리 영역의 데이터를 쓰고 있는데 또 다른 스레드가 같은 메모리 영역의 데이터를 읽거나 쓸 경우 발생할 수 있는 문제이다 동시성 문제는 싱글스레드에서는 절대 발생하지 않으며 멀티 스레드를 운용하는 어플리케이션에서 나타나는 현상이다 a는 여러 쓰레드가 접근 가능하다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/021_synchronized_cpu/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/021_synchronized_cpu/</guid>
      <description>강의 메모 - 동기화와 CPU 관계 # 동기화 (synchronization)란&#xA;프로세스 혹은 스레드 간 공유 영역에 대한 동시접근으로 인해 발생하는 데이터 불일치(data inconsistency) 를 막고 데이터 일관성을 유지하기 위해 순차적으로 공유 영역을 수행하도록 보장하는 메카니즘이라 할 수 있다 CPU 연산 처리 이해&#xA;모든 기계어 명령(machine instruction) 은 원자성(atimicity) 을 갖는데 이는 하나의 기계어 명령어가 실행을 시작할 경우 그 명령의 수행 종료 시 까지는 인터럽트(interrupt)를 받지 않는다. 분리 불가능(indivisible) 이라고도 한다 CPU 가 두 개 이상의 명령어를 처리할 경우에은 원자성이 보장되지 않는데 이는 각 명령을 수행하는 중에 OS 가 다른 스케줄링으로 CPU 에게 다른 명령을 수행하게 함으로써 현재 수행중인 명령을 인터럽트 즉 중단하게 된다는 의미이다 두 개 이상의 명령어를 원자성으로 묶기 위해서는 스레드 간 동기화 메카니즘이 필요하다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/022_critical_section/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/022_critical_section/</guid>
      <description>강의 메모 - ThreadLocal - 1,2 # Critical Section (임계영역, 공유변수영역) # Critical Section 이란 둘 이상의 스레드가 동시에 접근해서는 안되는 공유 자원(자료 구조 또는 장치) 에 접근하는 코드 영역를 말한다. 임계영역은 entry section, critical section, exit section, remainder section 으로 구성 된다 입장영역(entry section) : critical section 에 진입하기 위해 진입허가를 요청하는 영역입니다. 임계영역(critical section) : 하나의 스레드만 접근할 수 있는 영역이다 퇴장영역(exit section) : critical section 에서 빠져나올 때 신호를 알리는 영역이다 나머지영역(remainder section) : entry section, critical section, exit section 을 제외한 나머지 영역이다 lock을 획득해야만, 임계영역에 진입 가능하다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/023_thread_safe/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/023_thread_safe/</guid>
      <description>강의 메모 - ThreadLocal - 1,2 # 개요 # 여러 스레드에서 클래스나 객체에 동시에 접근해서 계속 실행하더라도 지속적인 정확성이 보장되는 코드를 스레드 세이프(thread-safe) 즉 스레드에 안전하다고 한다. 동시에 실행해도 동일한 결과값 기본적으로 클래스 명세에 스레드 안정성을 헤치는 코드나 상태를 가지고 있지 않으면 스레드에 안전하다라고 정의할 수 있다 스레드에 안전한 코드에는 경쟁상태가 없으며 경쟁 상태는 다수의 스레드가 공유 자원에 쓰기 작업을 시도할 때 발생하기 때문에 스레드가 실행될 때 어떤 자원을 공유하게 되는지 아는 것이 중요하다 스레드에 안전한 구조 # 임계영역을 동기화 한다</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/017_thread_type/</link>
      <pubDate>Sun, 14 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/017_thread_type/</guid>
      <description>강의 메모 - 사용자 스레드 vs 데몬 스레드 # 개요 # 자바에는 크게 두 가지 유형의 스레드로 구분할 수 있는데 바로 사용자 스레드(user thread)와 데몬 스레드(daemon thread)이다. 사용자 스레드는 사용자 스레드를 낳고 데몬 스레드는 데몬 스레드를 낳는다.즉 자식 스레드는 부모 스레드의 상태를 상속 받는다 자바 어플리케이션이 실행이 되면 JVM 은 사용자 스레드인 메인스레드와 나머지 데몬 스레드를 동시에 생성하고 시작한다 main thread # 메인 스레드는 어플리케이션에서 가장 중요한 부분으로서 어플리케이션을 실행할 때마다 메인 스레드가 생성되어 실행된다 메인 스레드는 어플리케이션을 실행하는 최초의 스레드이자 어플리케이션 실행을 완료하는 마지막 스레드의 역할을 한다 메인 스레드에서 여러 하위 스레드를 추가로 시작할 수 있고 하위 스레드는 또 여러 하위 스레드를 시작할 수 있다 메인 스레드가 사용자 스레드이기 때문에 하위 스레드는 모두 사용자 스레드가 된다 user thread (사용자 스레드) # 사용자 스레드는 메인 스레드에서 직접 생성한 스레드를 의미한다 사용자 스레드는 각각 독립적인 생명주기를 가지고 실행하게 되며 메인 스레드를 포함한 모든 사용자 스레드가 종료하게 되면 어플리케이션이 종료하게 된다 사용자 스레드는 foreground 에서 실행되는 높은 우선순위를 가지며 JVM은 사용자 스레드가 스스로 종료될 때까지 어플리케이션을 강제로 종료하지 않고 기다린다 자바가 제공하는 스레드 풀인 ThreadPoolExecutor 은 사용자 스레드를 생성한다 daemon thread (데몬 스레드) # 데몬 스레드는 JVM 에서 생성한 스레드이거나 직접 데몬 스레드로 생성한 경우를 말한다 모든 사용자 스레드가 작업을 완료하면 데몬 스레드의 실행 여부에 관계없이 JVM 이 데몬 스레드를 강제로 종료하고 어플리케이션이 종료한다 데몬 스레드의 생명주기는 사용자 스레드에 따라 다르며 낮은 우선순위를 가지고 background 에서 실행된다 데몬 스레드는 사용자 스레드를 보조 및 지원하는 성격을 가진 스레드로서 보통 사용자 작업을 방해하지 않으면서 백그라운드에서 자동으로 작동되는 기능을 가진 스레드이다 자바가 제공하는 스레드 풀인 ForkJoinPool 은 데몬 스레드를 생성한다 데몬 스레드 생성 # void setDaemon(boolean on) 스레드를 데몬 또는 비데몬 스레드로 표시하며 이 메소드는 반드시 스레드가 시작되기 전에 호출되어야 한다 스레드가 실행 중인 동안 setDaemon()을 호출하려고 하면 IllegalThreadStateException 이 발생한다 true 이면 데몬스레드가 되며 false 이면 사용자 스레드가 된다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/018_thread_group/</link>
      <pubDate>Sun, 14 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/018_thread_group/</guid>
      <description>강의 메모 - ThreadGroup # 개요 # 자바는 스레드 그룹(ThreadGroup)이라는 객체를 통해서 여러 스레드를 그룹화하는 편리한 방법을 제공한다 ThreadGroup은 스레드 집합을 나타내며 스레드 그룹에는 다른 스레드 그룹도 포함될 수 있고 그룹 내의 모든 스레드는 한 번에 종료하거나 중단할 수 있다 스레드는 반드시 하나의 스레드 그룹에 포함되어야 하며 명시적으로 스레드 그룹에 포함시키지 않으면 자신을 생성한 스레드가 속해 있는 스레드 그룹에 포함되어 진다 일반적으로 사용자가 main 스레드에서 생성하는 모든 스레드는 기본적으로 main 스레드 그룹에 속하게 된다 코드로 별도 스레드를 만들면 기본적으로 main 스레드 그룹에 속해진다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/019_threadLocal/</link>
      <pubDate>Sun, 14 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/019_threadLocal/</guid>
      <description>강의 메모 - ThreadLocal - 1,2 # 개요 # 자바에서 스레드는 오직 자신만이 접근해서 읽고 쓸수 있는 로컬 변수 저장소를 제공하는데 이를 ThreadLocal 이라고 한다 각 스레드는 고유한 ThreadLocal 객체를 속성으로 가지고 있으며 ThreadLocal 은 스레드 간 격리되어 있다 스레드는 ThreadLocal 에 저장된 값을 특정한 위치나 시점에 상관없이 어디에서나 전역변수처럼 접근해서 사용할 수 있다. 변수 값을 전달하지 않아도 된다 모든 스레드가 공통적으로 처리해야 하는 기능이나 객체를 제어해야 하는 상황에서 스레드마다 다른 값을 적용해야 하는 경우 사용한다 (인증 주체 보관, 트랜잭션 전파, 로그 추적기 등) Thread 마다 ThreadLocal을 가지고있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/012_thread_interrupt/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/012_thread_interrupt/</guid>
      <description>강의 메모 - interrupt() # 개요 # Interrupt 의 사전적 의미는 ‘방해하다’ 라는 뜻으로 어떤 주체의 행동이나 실행흐름을 방해한다는 의미로 해석 할 수 있다 자바 스레드에서 interrupt() 는 특정한 스레드에게 인터럽트 신호를 알려 줌으로써 스레드의 실행을 중단하거나, 작업 취소, 강제 종료 등으로 사용할 수 있다 interrupt() # interrupt() 는 스레드에게 인터럽트가 발생했다는 신호를 보내는 메카니즘이다 interrupt() 는 스레드가 현재 실행 흐름을 멈추고 인터럽트 이벤트를 먼저 처리하도록 시그널을 보내는 장치라 할 수 있다 interrupted 속성 스레드는 인터럽트 상태(Interrupt State )로 알려진 interrupted 를 가지고 있으며 인터럽트 발생 여부를 확인할 수 있는 상태 값이다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/013_thread_info/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/013_thread_info/</guid>
      <description>강의 메모 - name() / currentThread() / isAlive() # Thread Name # 멀티 스레드 환경에서 어떤 스레드가 실행 중인지 알아야 할 경우 스레드에 사용자 이름을 지정하면 실행 중인 스레드를 쉽게 찾을 수 있다 디버깅할 때 어떤 스레드가 무슨 작업을 하고 있는지 정확하게 파악하기 위해서 스레드 이름을 정하는 것이 큰 도움이 된다 자바에서 스레드가 생성되면 스레드 이름이 자동으로 주어진다. 이건 사용자가 정하는 것이 아니다 가장 먼저 생성되는 메인 스레드의 이름은 main 이다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/014_thread_priority/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/014_thread_priority/</guid>
      <description>강의 메모 - Priority # 스레드 우선순위 (Priority) # 단일 CPU에서 여러 스레드를 실행하는 것을 스케줄링이라고 하며 스레드는 스케줄링에 의해 선점되어 CPU 를 할당받는다&#xA;자바 런타임은 고정 우선순위 선점형 스케줄링(fixed-priority pre-emptive scheduling ) 으로 알려진 매우 단순하고 결정적인 스케줄링 알고리즘을 지원한다&#xA;이 알고리즘은 실행 대기 상태의 스레드 중에 상대적인 우선 순위에 따라 스레드를 예약한다&#xA;우선순위 개념&#xA;Java에서 스레드의 우선 순위는 1에서 10 사이의 정수이며 정수 값이 높을수록 우선순위가 높다 스레드가 생성될 때 우선순위 값이 정해지며 기본 우선 순위인 5 로 설정된다 스케줄러는 우선순위가 높은 스레드를 실행하다가 해당 스레드가 중지, 양보 또는 실행 불가능이 되는 경우 우선 순위가 낮은 스레드를 실행하기 시작한다 두 스레드의 우선순위가 같을 경우 라운드 로빈(순환 할당) 스케줄링 방식에 의해 다음 스레드를 선택한다 스케줄러가 반드시 우선순위가 높은 스레드를 실행한다고 보장 할 수 없다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/015_thread_uncaughtExceptionHandler/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/015_thread_uncaughtExceptionHandler/</guid>
      <description>강의 메모 - 스레드 예외처리 - UncaughtExceptionHandler # 개요 # 기본적으로 스레드의 run() 은 예외를 던질 수 없기 때문에 예외가 발생할 경우 run() 안에서만 예외를 처리해야 한다 RuntimeException 타입의 예외가 발생할 지라도 스레드 밖에서 예외를 캐치할 수 없고 사라진다 스레드가 비정상적으로 종료되었거나 특정한 예외를 스레드 외부에서 캐치하기 위해서 자바에서는 UncaughtExceptionHandler 인터페이스를 제공한다 UncaughtExceptionHandler # 캐치 되지 않는 예외에 의해 Thread가 갑자기 종료했을 때에 호출되는 핸들러 인터페이스 어떤 원인으로 인해 스레드가 종료되었는지 대상 스레드와 예외를 파악할 수 있다 예외가 발생하면 uncaughtException 이 호출되고 대상 스레드 t 와 예외 e 가 인자로 전달된다 Thread API # static void setDefaultUncaughtExceptionHandler</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/016_thread_stop_flag/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/016_thread_stop_flag/</guid>
      <description>강의 메모 - 스레드 중지 – flag variable vs interrupt() - 1,2 # 개요 # 자바에서는 무한 반복이나 지속적인 실행 중에 있는 스레드를 중지하거나 종료할 수 있는 API 를 더 이상 사용할 수 없다 (suspend(), stop()) 수행 중에 강제로 종료해버리면 이슈가 생길 수 있기 때문 스레드를 종료하는 방법은 플래그 변수를 사용하거나 interrupt() 를 활용해서 구현할 수 있다 Flag Variable # 플래그 변수의 값이 어떤 조건에 만족할 경우 스레드의 실행을 중지하는 방식 플래그 변수는 동시성 문제로 가능한 atomic 변수나 volatile 키워드를 사용하도록 한다 동시성 문제 때문 running 변수는 여러 쓰레드가 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/011_thread_join/</link>
      <pubDate>Mon, 08 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/011_thread_join/</guid>
      <description>강의 메모 - join() # 개요 # join() 메서드는 한 스레드가 다른 스레드가 종료될 때까지 실행을 중지하고 대기상태에 들어갔다가 스레드가 종료되면 실행대기 상태로 전환된다 T1, T2가 있을때, T1이 T2의 모든 작업이 종료될때까지 대기했다가, T2의 작업이 다 끝나고나서 T1이 본인의 작업을 이어서 나가야할 경우 T1 기준으로 T2.join()을 수행 대기는 T1이 하는것 스레드의 순서를 제어하거나 다른 스레드의 작업을 기다려야 하거나 순차적인 흐름을 구성하고자 할 때 사용할 수 있다 Object 클래스의 wait() 네이티브 메서드로 연결되며 시스템 콜을 통해 커널모드로 수행한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/010_thread_sleep/</link>
      <pubDate>Sun, 07 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/010_thread_sleep/</guid>
      <description>강의 메모 - sleep() # 개요 # 지정된 시간 동안 현재 스레드의 실행을 일시 정지하고 대기상태로 빠졌다가 시간이 지나면 실행대기 상태로 전환된다 native 메서드로 연결되며 시스템 콜을 통해 커널모드에서 수행 후 유저모드로 전환한다 이 간단한 메서드 자체도 jvm 자체에서 실행되지 못하고 커널모드에서 수행된다. 컨텍스트 스위칭 발생 API 및 예외 # staic sleep(long millis) throws InterruptedException # 지정한 밀리초 시간 동안 스레드를 수면 상태로 만든다 밀리초에 대한 인수 값은 음수가 될 수 없으며 음수 일 경우 IllegalArgumentException 이 발생한다</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/etc/003_huge_traffic_handling/</link>
      <pubDate>Sat, 06 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/etc/003_huge_traffic_handling/</guid>
      <description>우아콘 2023, 우아한 형제들 세션 정리 # 대규모 트랜잭션을 처리하는 배민 주문시스템 규모에 따른 진화 # 성장통들 # 개선 대상 리스트 단일 장애 포인트 대용량 데이터 대규모 트랜잭션 복잡한 이벤트 아키텍처 단일 장애 포인트 # 루비라 불리는 중앙 집중 저장소에 모든 시스템이 의존 중앙 저장소의 부하 발생 해결 # 중앙 저장소 -&amp;gt; 각 시스템을 분리하는 프로젝트 진행 시스템 간 통신은 Message Queue 기반으로 통신 특정 시스템의 장애는 메시지 발행의 실패로 끝 정리 # 중앙 집중 DB의 장애, 전체 시스템의 전파 -&amp;gt; MQ를 이용한 이벤트 기반 통신으로 시스템간 영향도를 분리</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/springbatch/001_springbatch_start/</link>
      <pubDate>Sat, 06 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/springbatch/001_springbatch_start/</guid>
      <description>강의메모 # 스프링 배치 소개 # 탄생 배경 # 자바 기반 표준 배치 기술 부재 스프링 배치는 SpringSource(현재는 Pivotal)와 Accenture(경영 컨설팅 기업)의 합작품 Accenture - 배치 아키텍처를 구현하면서 쌓은 기술적인 경험과 노하우 SpringSource - 깊이 있는 기술적 기반과 스프링의 프로그래밍 모델 배치 핵심 패턴 # Read(데이터 조회), Process(데이터 가공), Write(데이터 저장) 배치 시나리오 # 배치 프로세스를 주기적으로 커밋 동시 다발적인 Job 의 배치 처리, 대용량 병렬 처리 실패 후 수동 또는 스케줄링에 의한 재시작 의존관계가 있는 step 여러 개를 순차적으로 처리 조건적 Flow 구성을 통한 체계적이고 유연한 배치 모델 구성 반복, 재시도, Skip 처리 아키텍처 # 도서 - 스프링배치 완벽가이드 # 1장.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/009_thread_status/</link>
      <pubDate>Thu, 04 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/009_thread_status/</guid>
      <description>강의 메모 - 스레드 생명주기와 상태 # 개요 # 자바 스레드는 생성, 실행, 종료에 따른 상태를 가지고있다. OS 스레드 상태를 의미하지 않는다. 자바 스레드는 어떤 시점이던 6가지 상태 중 오직 1개의 상태를 가질 수 있다. 자바 스레드의 현재 상태를 가져오려면 Thread의 getState() 메서드를 사용하여 가져올 수 있다. Thread 클래스에는 스레드 상태에 대한 ENUM 상수를 정의하는 Thread.State 클래스를 제공한다. 스레드 상태 # NEW : 객체만 생성된 상태 RUNNABLE WAITING : 대기는 언제하는가?</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/008_thread_start/</link>
      <pubDate>Wed, 03 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/008_thread_start/</guid>
      <description>강의 메모 - 스레드 실행 및 종료 # 개요 # 자바 스레드는 OS 스케줄러에 의해 실행 순서가 결정되며, 스레드 실행 시점을 JVM에서 제어할 수 없다. kernel이 제어한다. 새로운 스레드는 현재 스레드와 독립적으로 실행되고, 최대 한번 시작할 수 있고, 스레드가 종료된 이후에는 다시 시작할 수 없다.&#xA;스레드 실행 # start() : 스레드를 실행시키는 메서드로 시스템 콜을 통해서 커널에 커널 스레드 생성을 요청한다.&#xA;start() 호출 후 System Call -&amp;gt; (execute) -&amp;gt; Kernel -&amp;gt; (create) -&amp;gt; Kernel Thread 순서</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/004_cpu_bound_io_bound/</link>
      <pubDate>Tue, 02 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/004_cpu_bound_io_bound/</guid>
      <description>강의 메모 - CPU Bound &amp;amp; I/O Bound # 개요 # 프로세스는 CPU 작업과 I/O 작업의 연속된 흐름으로 진행된다.&#xA;CPU 작업 # I/O 작업 # 파일을 읽는 행위 등 CPU는 실제 데이터를 읽어들이는 일을 하진 않고, 이를 다른 디바이스에 맡긴다. CPU는 다시금 연산작업을 할 수 있는 쓰레드를 할당받고, CPU는 그 쓰레드에게 실제 연산작업을 시킨다. I/O 작업이 일어날 경우, CPU는 다른 쓰레드를 선택하는거고, 해당 I/O 작업을 하고있는 쓰레드는 I/O 작업이 끝날때까지 기다려야한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/005_user_kernel_systemcall/</link>
      <pubDate>Tue, 02 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/005_user_kernel_systemcall/</guid>
      <description>강의 메모 - 사용자 모드 &amp;amp; 커널 모드 # 개요 # 운영체제 : 컴퓨터 시스템의 자원을 효율적으로 관리하는 소프트웨어 운영체제의 여러 기능 중 핵심 기능을 담당하는 부분을 커널(kernel) 이라고 한다.&#xA;사용자가 운영체제 위에서 실행되는 프로그램을 편하고 효율적으로 사용할 수 있게 하드웨어와 소프트웨어 간 중개자 역할을 한다. CPU, I/O 장치, 메모리, 저장소와 같은 하드웨어 자원을 프로그램에 잘 할당하는 데 있다. 운영체제는 응용 프로그램이 하드웨어 자원에 직접 접근하는 것을 방지하여 자원을 보호한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/006_user_mode_kernel_mode_thread/</link>
      <pubDate>Tue, 02 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/006_user_mode_kernel_mode_thread/</guid>
      <description>강의 메모 - 사용자 수준 스레드 &amp;amp; 커널 수준 스레드 # 개요 # 스레드는 사용자 수준 스레드(User Level Thread), 커널 수준 스레드(Kernel Level Thread) 로 구분된다. 사용자 수준 스레드 : 사용자 프로그램에서 관리하는 스레드 커널 수준 스레드 : OS에서 관리하는 스레드 ** CPU의 할당 단위는 쓰레드다. **&#xA;사용자 수준 스레드(User Level Thread) # 스레드 라이브러리(Pthreads, WIndows Threads, Java Threads(JVM))에 의해 스레드의 생성, 종료, 스레드간 메시지 전달, 스케줄링 스레드 보관 등 모든 것을 관리한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/007_java_thread/</link>
      <pubDate>Tue, 02 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/007_java_thread/</guid>
      <description>강의 메모 - Java Thread Fundamentals &amp;gt; 스레드 생성 # 개요 # 자바 스레드는 JVM에서 User Thread를 생성할때 시스템 콜을 통해서 커널에 생성된 Kernel Thread와 1:1 매핑이 되어 최종적으로 커널에서 관리된다. JVM에서 스레드를 생성할때마다 커널에서 자바 스레드와 대응하는 커널 스레드를 생성한다. 자바에서 Platform Thread으로 정의되어 있다. 즉, OS 플랫폼에 따라 JVM이 사용자 스레드를 매핑하게 된다. Platform Thread : 운영체제에서 스케줄링되는 Kernel 쓰레드와 1:1 매핑된 플랫폼 쓰레드의 생성을 지원한다. 사용자 수준 쓰레드처럼 쓰레드 관리, 스케줄링 등을 하지않고, 생성만 하고 커널 쓰레드와 매핑만 되어있음 (커널의 제어를 받는다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/003_context_switching/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/003_context_switching/</guid>
      <description>강의 메모 - ContextSwitching # 개요 # 하나의 CPU는 동일한 시간에 1개의 task만 수행 가능, 여러 프로세스를 동시에 실행X 하나의 CPU에서 여러 프로세스를 동시성으로 처리하기 위해서는 한 프로세스에서 다른 프로세스로 전환해야하는데, 이것을 컨텍스트 스위칭이라고 한다.&#xA;Context # 프로세스 간 전환을 위해서는 이전에 어디까지 명령을 수행했고, CPU Register에는 어떤 값이 저장되어있는지에 대한 정보가 필요하다. Context는 CPU가 해당 프로세스를 실행하기 위한 프로세스의 정보를 의미하며, 이 정보들은 운영체제가 관리하는 PCB라고 하는 자료구조의 공간에 저장된다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/etc/002_tps/</link>
      <pubDate>Thu, 28 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/etc/002_tps/</guid>
      <description>내가 만든 서비스는 얼마나 많은 사용자가 이용할 수 있을까? # 성능 테스트는 왜 해야 할까? # 성능 테스트 : 서비스의 성능적인 부분을 측정하기 위해 실행되는 작업 애플리케이션의 성능을 측정 : 점진적인 부하를 가하는 과정 속에서 더 이상 처리량이 증가하지 않을 때, 그 수치를 측정하고 해석하는 것 목적 현재 애플리케이션이 최대 몇 명의 사용자를 수용할 수 있는지 측정하고, 그 결과가 최초 목표한 성능에 부합하는지 알아내기 위함 목표 성능에 부합하지 않는다면 어떤 지점에서 병목이 발생하고, 이를 해결하기 위해 무엇을 해야 하는지 분석하여 개선함으로써 최종적으로 서비스가 중단되는 상황 없이 제공될 수 있도록 가용성을 높이는 것 서비스가 빠른지 느린지 어떻게 알 수 있을까?</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/redis/008_spring_session_redis/</link>
      <pubDate>Mon, 25 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/redis/008_spring_session_redis/</guid>
      <description>tech blog 글 읽고 정리하기 # 제목은 Spring Session 도입기로 하겠습니다. 근데 이제 Redis를 곁들인 # 개요 # 줌인터넷의 회원 서비스는 분산 환경에서 운영되고있다. 분산 환경에서 세션 동기화 문제를 해결하기 위해 사용하고 있는 세션 저장소를 Redis로 교체하게 된 이유와 기존 아키텍처를 유지하면서 안정적으로 Spring Session으로 도입할 수 있는 방법을 소개한다.&#xA;도입 배경 # 기존 Aerospike -&amp;gt; Redis로의 전환을 결정하게 되었다. 전환을 통해 바라는 점&#xA;Spring Session의 도입 가능 Spring Session은 Redis 이외에도 다양한 세션 저장소를 지원하여 세션 정보를 유연하게 관리할 수 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/001_process_thread/</link>
      <pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/001_process_thread/</guid>
      <description>강의 메모 - Process &amp;amp; Thread # Process # File down -&amp;gt; .exe 파일 실행 -&amp;gt; 설치된 상태 : 프로그램 (!= 프로세스) 프로세스는 프로그램의 실제 실행. =&amp;gt; 프로그램 데이터들이 메모리에 올라와 CPU를 할당받고 명령을 수행하고있는 상태&#xA;각각의 프로세스는 RAM(메모리)의 각각의 영역을 할당받음&#xA;4GB 정도 할당 받는다고 해보자.&#xA;1GB 정도는 운영체제를 위한 커널(Kernel) 서비스를 위해 차지한다. 나머지 3GB가 Stack, heap, data, code 등 영역을 차지한다. 프로세스는 자식 프로세스를 가질 수 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/002_parallel_concurrent/</link>
      <pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/002_parallel_concurrent/</guid>
      <description>강의 메모 - Parallel &amp;amp; Concurrent # 동시성 # 특정한 순서 없이 겹치는 기간에 시작, 실행 및 완료되는 여러 작업에 관한것 ex) 사람이 있다. 작업1, 작업2가 있다. 이 사람은 작업1, 작업2를 모두 해야한다. 작업1을 하고 작업2를 하는데, 시간적으로 동시에하는건 아니고 계속 번갈아가면서 한다. 이게 짧은 찰나로 번갈아가면서 하기 때문에 동시에 하는것처럼 보인다. (순차적이지 않다. 순서가 없다.) (시간적인 동시성이 아님)&#xA;작업의 갯수 &amp;gt; CPU 갯수 Thread1, Thread2가 번갈아가면서 Task를 수행 빠른게 목적이 아닌, CPU의 효율적인 사용이 목적이다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/redis/007_redis_cluster_migration/</link>
      <pubDate>Thu, 21 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/redis/007_redis_cluster_migration/</guid>
      <description>tech blog 글 읽고 정리하기 # 초보 개발자를 위한 Redis Cluster Migration 가이드라인 # 요청상황 # Master/Slave 구조의 Redis에서 Cluster 구조의 Redis로 migration 되니, 관련 코드 작업을 진행해야한다. 즉, Master/Slave에는 모든 key가 한 node에 있고 Cluster는 그렇지 않은 상황이다.&#xA;Master/Slave 구조와 Cluster 구조 # Master/Slave 구조&#xA;Master의 내용을 Slave에 복제하여 read/write 권한을 나눠 사용하는 구조 어떤 key가 들어오든 간에 하나의 master에서 처리를 진행 Cluster 구조&#xA;여러대의 Master를 두어 가용성을 높인 구조 하나의 Master가 fail되면 짝을 이루고있던 Slave가 Master로 승격되어 가용성을 보장하는 구조 일반적으로 Cluster 구조에서는 3개의 node를 구성해서 사용 (경우에 따라 node의 개수 변경 가능) key를 hash한 값에 따라 들어가는 master node가 달라진다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/etc/001_jmeter/</link>
      <pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/etc/001_jmeter/</guid>
      <description>설치 # Jmeter 설치 터미널에서 수행 brew install jmeter jmeter 실행 터미널에서 수행 open /opt/homebrew/bin/Jmeter 사용방법 # Request Number Of Thread (users) : 몇 개의 쓰레드(유저 수)로 테스트할 지 Ramp-up period (seconds) : {Number of Thread} 만큼의 쓰레드를 몇초에 걸쳐서 만들 지 Loop Count : 요청을 몇번을 반복할 지 (설정된 값에 따라 Number of Threads * Ramp-up period 만큼 요청을 다시 보낸다.) Response Label : Sampler 명 Samples : 샘플 실행 수 (Number of Threads X Ramp-up period) Average : 평균 걸린 시간 (ms) Min : 최소 Max : 최대 Std.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/rdbms/004_window_function/</link>
      <pubDate>Mon, 18 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/rdbms/004_window_function/</guid>
      <description>Analytic SQL - 집계(Aggregate) Analytic과 Window 상세 # Aggregate Functions vs Window Functions # Aggregate Functions Group by는 원본 데이터 집합의 레벨을 변경하여 적용 Window Functions Analytic SQL은 원본 데이터 집합의 레벨을 그대로 유지하면서 적용 Window를 이용하여 Row 단위의 집합 연산 수행 가능 원본 데이터의 레벨을 그대로 유지하면서, 그룹핑 레벨에서 자유롭게 Window의 이동과 크기를 조절하면서 Analytic을 수행 Analytic SQL 적용 로직 # &amp;lt;Analytic function&amp;gt; (인자1, ...) OVER ( [Partition절] [Sorting절] [Window절] ) 자유로운 window 설정에 따른 analytic 구사가 가능하므로, SQL의 Analytic 함수를 window 함수로도 지칭한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/rdbms/005_subquery/</link>
      <pubDate>Mon, 18 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/rdbms/005_subquery/</guid>
      <description>섹션 8. 서브 쿼리(Sub-query) # 서브쿼리(Sub-query) # 서브쿼리는 하나의 쿼리 내에 또다른 쿼리가 포함되어있는 쿼리를 의미 서브 쿼리는 메인 쿼리(Main Query) 내에 포함되어있는 관계 Where절에 사용될 경우 복잡한 업무적인 조건을 직관적인 SQL로 표현하여 필터링하는데 주로 사용됨 서브쿼리 유형 # Where절에 사용되는 서브쿼리 -- 평균 급여 이상의 급여를 받는 직원 select * from hr.emp where sal &amp;gt;= (select avg(sal) from hr.emp); -- 가장 최근 급여 정보 select * from hr.emp_salary_hist a where todate = (select max(todate) from hr.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/clean_code/001_argument/</link>
      <pubDate>Sun, 17 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/clean_code/001_argument/</guid>
      <description>tech blog 글 읽고 정리하기 # 인자가 많은 메서드는 왜 나쁠까? # 상황 # 재전송, 메일 수신자 필터링, SMS 전송(fallback) 등 다양한 기능을 제공하는 메일 발송 기능이 있을때. 이 기능을 하는 메서드의 인자가 11개 정도 있다면?&#xA;class Mail( // ... ) { fun send( phoneFallback: Boolean?, phoneNumber: String?, isForceSend: Boolean?, recipient: String, id: Long, mailDomainFilterService: MailDomainFilterService?, mailRetryService: MailRetryService?, title: String, body: String, param: Map&amp;lt;Any, Any&amp;gt;, reservedAt: Instant?, ) } 위 클래스를 다음과 같이 호출한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/rdbms/001_basic_join/</link>
      <pubDate>Sun, 17 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/rdbms/001_basic_join/</guid>
      <description>조인(Join) - 조인 기반 메커니즘 # 조인 # 2개 이상의 테이블을 서로 연결하여 데이터 추출 관계형 DB에서는 조인을 통해 서로 다른 테이블간의 정보를 원하는 대로 가져올 수 있음 중요한 부분 # 1:M 조인시, 결과 집합은 M 집합의 레벨을 그대로 유지한다. 조인 결과 : M 집합 Left Outer Join # Right Outer Join은 사용하지 말자. -&amp;gt; 테이블 위치를 바꾸면 Left Outer join처럼 사용 가능 Left Outer Join 또다른 표기 (+) # SELECT * FROM TEST1 A, TEST2 B WHERE A.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/rdbms/002_date_interval/</link>
      <pubDate>Sun, 17 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/rdbms/002_date_interval/</guid>
      <description>Date, Timestamp, Interval 다루기 # Date 일자로서 년, 월, 일 정보를 가짐. YYYY-MM-DD Timestamp 일자를 시간 정보까지 같이 가짐. YYYY-MM-DD HH24:MI:SS Time 오직 시간 정보만 가짐. HH24:MI:SS Interval N days HH24:MI_SS pattern # hh24 하루중 시간(00-23) hh12 하루중 시간(01-12) mi 분(00-59) ss 초(00-59) yyyy 년도 mm 월(01-12) dd 일(월중 일자 01-31) month 월 이름 day 요일 이름 w 월의 주(1-5) ww 년의 주(1-52) d 요일. 일요일(1) ~ 토요일(7) am 또는 pm AM 또는 PM 표시 tz 시간대 interval 활용 # Date 타입에 숫자값을 더하거나/빼면 숫자값에 해당하는 일자를 더하거나/빼서 날짜 계산 곱셈/나눗셈은 불가능 -- DATE 타입에 곱하기나 나누기는 할 수 없음.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/rdbms/003_groupby/</link>
      <pubDate>Sun, 17 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/rdbms/003_groupby/</guid>
      <description>Group by 와 집계 함수(Aggregate Function) # Group by절 # Group by 절에 기술된 컬럼 값(또는 가공 컬럼값)으로 그룹화 한 뒤 집계(Aggregation) 함수와 함께 사용되어 그룹화된 집계 정보를 제공 Group by 절에 기술된 컬럼 값으로 반드시 1의 집합을 가지게 됨 Select 절에는 Group by 절에 기술된 컬럼(또는 가공 컬럼)과 집계 함수만 사용될 수 있음 Null을 계산하지 않음 case~when 사용한 pivoting # Group by 시 행 레벨로 만들어진 데이터를 열 레벨로 전환할 때 Aggregate와 case when을 결합하여 사용 -- DEPTNO로 GROUP BY하고 JOB으로 PIVOTING SELECT SUM(CASE WHEN JOB = &amp;#39;SALESMAN&amp;#39; THEN SAL END) AS SALES_SUM , SUM(CASE WHEN JOB = &amp;#39;MANAGER&amp;#39; THEN SAL END) AS MANAGER_SUM , SUM(CASE WHEN JOB = &amp;#39;ANALYST&amp;#39; THEN SAL END) AS ANALYST_SUM , SUM(CASE WHEN JOB = &amp;#39;CLERK&amp;#39; THEN SAL END) AS CLERK_SUM , SUM(CASE WHEN JOB = &amp;#39;PRESIDENT&amp;#39; THEN SAL END) AS PRESIDENT_SUM FROM HR.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/batch/002_batch_performance/</link>
      <pubDate>Sat, 16 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/batch/002_batch_performance/</guid>
      <description>[Youtube 세미나 보기] Batch Performance 극한으로 끌어올리기: 1억 건 데이터 처리를 위한 노력 / if(kakao)2022 # 다루고자 하는 내용 # 개발자들은 언제 Batch를 개발할까? 특정 시간에 많은 데이터를 일괄 처리 배치를 사용하는 상황 일괄 생성 일괄 수정 통계 무관심한 Batch Performance # Batch 개발을 쉽게 생각하는 경향 배포후 관리 소홀 배치를 지원하는 APM Tool의 부재 많은 데이터 처리량 # 2017년 : 하루 평균 25만번 현재 : 1억번 그럼에도 Batch 수행시간은 1시간으로 동일하다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/msa/003_circuit_breaker/</link>
      <pubDate>Fri, 15 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/msa/003_circuit_breaker/</guid>
      <description>Spring cloud circuit breaker # Circuit breaker # 전기 회로의 차단기와 유사한 역할을 하는 소프트웨어 디자인 패턴 특정 서비스가 과부하 상태가 되었을 때 추가적인 요청을 차단하여 시스템의 안정성을 유지 해당 서비스가 복구될 수 있는 시간 확보 Reactive systems의 Resilient(복원력)를 지원 Spring Cloud Circuit Breaker # Spring에서 circuit breaker를 지원하기 위해 만든 라이브러리 resilience4j와 spring retry를 추상화하여 Circuit breaker를 지원 reactive 환경에서는 resilience4j 만 사용 가능 Resilience4j # java에서 circuit breaker를 지원하는 라이브러리 Circuit breaker, Rate Limiter, Retry, Bulkhead, Time Limiter, Cache 등의 기능을 제공 Circuit breaker 준비 # org.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/operating_system/001_thread/</link>
      <pubDate>Fri, 15 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/operating_system/001_thread/</guid>
      <description>스레드 종류 - 하드웨어 스레드, OS 스레드, 네이티브 스레드, 커널 스레드, 유저 스레드, 그린 스레드 # 우리가 작성한 프로그램의 동작방식 # 하드웨어 OS Kernel User Program : 운영체제를 통해 하드웨어를 사용 Hardware thread # 코어(core)의 고민 : 메모리에서 데이터를 기다리는 시간이 꽤 오래 걸린다. 코어에서 프로그램이 실행될때 각종 연산 작업이 있을테고, 이를 위해 메모리에 접근하는 작업들이 있다. 이 코어에서 실행되는 연산 작업에 비해 메모리에서 데이터를 기다리는 시간이 더 오래 걸린다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/msa/001_reactive/</link>
      <pubDate>Thu, 14 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/msa/001_reactive/</guid>
      <description>1. Reactive Mircroservice의 Reactive # Spring cloud # Reactive systems의 핵심 가치 # Responsive(응답성) # 요구사항 문제를 신속하게 탐지하고 효과적으로 대처 신속하고 일관성 있는 응답 시간 제공 신뢰할 수 있는 상한선을 설정하여 일관된 서비스 품질을 제공 결과 가능한 한 즉각적으로 응답 사용자의 편의성과 유용성의 기초 오류 처리를 단순화 일반 사용자에게 신뢰를 조성하고, 새로운 상호작용 촉진 Resilient(복원력) # 요구사항 복제, 봉쇄, 격리, 위임에 의해 실현 장애는 각각의 구성 요소에 포함 (봉쇄) 구성 요소들은 서로 분리 (격리) 복구 프로세스는 다른(외부의) 구성 요소에 위임 (위임) 필요한 경우 복제를 통해 고가용성이 보장 (복제) 결과 장애에 직면하더라도 응답성을 유지 시스템이 부분적으로 고장이 나더라도, 전체 시스템 을 위험하게 하지 않고 복구 할 수 있도록 보장 구성 요소의 클라이언트는 장애를 처리하는데에 압박을 받지 않습니다 Elastic(유연성) # 요구사항 경쟁하는 지점이나 중앙 집중적인 병목 현상이 존재하지 않도록 설계 구성 요소를 샤딩하거나 복제하여 입력을 분산 실시간 성능을 측정하는 도구를 제공 응답성 있고 예측 가능한 규모 확장 알고리즘을 지원 결과 작업량이 변화하더라도 응답성을 유지 입력 속도의 변화에 따라 이러한 입력에 할당된 자원을 증가시키거나 감소 상품 및 소프트웨어 플랫폼에 비용 효율이 높은 방식으로 유연성을 제공 Message Driven(메시지 기반) # 비동기 통신: 구성 요소는 서로 비동기적으로 메시지를 주고 받으며, 독립적인 실행을 보장한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/msa/002_reactive_microservice/</link>
      <pubDate>Thu, 14 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/msa/002_reactive_microservice/</guid>
      <description>2. Reactive Mircroservice의 Microservice # Monolithic 아키텍쳐 # 모든 컴퍼넌트가 하나의 서버 내에 존재 단순성: 코드 저장소가 하나로 존재하는 경우가 많아서 관리 포인트가 줄어든다 일관성: 각각의 서비스는 하나의 기술 스택으로 제공되기 때문에 접근성이 높다 높은 효율: 서비스 사이에 네트워크 통신이 없기 때문에 네트워크 지연이나 데이터 직렬화에 의한 오버헤드가 없다 Monolithic 아키텍쳐의 단점 # 확장성의 한계: 모든 서비스가 하나의 서버로 구성되어 있기 때문에 특정 서비스가 부하를 받더라도 서버 전체를 늘려야 한다 장애의 전파: 서비스 중 한 곳에서 문제가 발생하면 시스템 전체에 영향을 줄 수 있다 배포의 단일화: 하나의 서비스를 변경하더라도 전체 시스템을 다시 배포해야 한다 기술의 정체: 모든 서비스가 하나의 코드베이스에 결합되어 있어서 새로운 기술을 도입하거나 아키텍쳐의 변경이 전체에 큰 영향을 줄 수 있다 유지보수의 어려움: 모든 구성요소가 직접 연결 되어 있기 때문에 작은 부분의 수정이 전체에 영향을 미칠 수 있다 Microservice 아키텍쳐 # 이러한 단점을 극복하기 위해 서비스와 저장 소, 데이터베이스 등을 분리 독립적인 배포: 각 서비스는 독립적으로 배포 유연한 확장: 각 서비스는 각각 탄력적으로 확장 가능.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/redis/003_reactive_redis_intro/</link>
      <pubDate>Thu, 14 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/redis/003_reactive_redis_intro/</guid>
      <description>1. Redis 소개 # Redis instance # 여러 client가 하나의 redis 서버로 요청 전달 단일 redis 서버에 문제가 발생하면 장애 -&amp;gt; 모든 client에서 접속 불가 Redis replication # master와 replica로 구성 master에 데이터가 업데이트 -&amp;gt; replica 동기화 replica : 읽기만 가능 replica에 문제 발생 -&amp;gt; 여러 node에 data가 복제되었기 때문에 복구 가능 master에 문제 발생 -&amp;gt; 개발자가 직접 replica 중 하나를 master로 변경 Redis sentinel # master에 문제 발생 -&amp;gt; replica들이 master를 선출 이전 master가 복구 된 경우, replica로 전환되어 새로운 master를 바라보게된다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/redis/004_Lettuce/</link>
      <pubDate>Thu, 14 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/redis/004_Lettuce/</guid>
      <description>2. Lettuce # 구조 # Reactor 기반으로 Reactive API 지원 Reactive streams API 지원 동기 API, 비동기 API 모두 지원 Netty 기반으로 높은 성능과 확장성 제공 일반 TCP 통신 뿐만 아니라 epoll, kqueue 기반의 multiplexing I/O 지원 주요 컴포넌트 # RedisClient : Redis의 연결 정보를 포함하는 객체 Netty의 Channel, EventLoopGroup 등을 포함하기 때문에 가능한한 재사용 RedisConnecction 생성 StatefulRedisConnection : Redis 서버 Connection 여러 쓰레드가 동시에 접근해도 안전 동기, 비동기, Reactive command를 제공 RedisReactiveCommand : Redis API와 관련된 reactive command 제공 RedisReactiveCommand 획득 # RedisClient.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/redis/005_ReactiveRedisTemplate/</link>
      <pubDate>Thu, 14 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/redis/005_ReactiveRedisTemplate/</guid>
      <description>3. ReactiveRedisTemplate # ReactiveRedisTemplate # ReactiveRedisTemplate은 Spring data redis reactive의 추상화 클래스 ReactiveRedisConnectionFactory를 통해서 RedisConnection을 주입 ReactiveRedisConnectionFactory # ReactiveRedisConnectionFactory는 RedisConnection을 제공 LettuceConnectionFactory와 JedisConnectionFactory 구현체 RedisTemplate bean # RedisReactiveAutoConfiguration를 통해서 자동으로 ReactiveRedisTemplate bean 생성 JdkSerializationRedisSerializer는 ObjectOutputStream을 이용하여 key와 value로 주어지는 object를 binary로 변환 key, value에 대해서 String만 지원하는 ReactiveStringRedisTemplate bean도 등록 ReactiveRedisOperations # ReactiveRedisConnection에 직접 접근할 수 있는 execute, executeInSession 메소드 pub/sub 메소드 key와 관련된 메소드 스크립트 메소드 operations 접근 메소드 pub/sub # convertAndSend: destination 채널로 message를 전달하고 메시지를 받은 클라이언트의 숫자를 반환 listenToChannel: channels에 주어진 채널들을 listen하고 메시지를 Flux 형태로 전달 key 관련 # hasKey: EXISTS.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/redis/006_ReactiveOperations/</link>
      <pubDate>Thu, 14 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/redis/006_ReactiveOperations/</guid>
      <description>4. ReactiveOperations # ReactiveValueOperations 실행 # set으로 특정 key에 value를 추가 setIfAbsent로 key에 값이 없을때만 설정 get으로 key의 value를 조회 multiGet으로 여러 key에 접근 increment로 특정 key의 value를 증가 ReactiveListOperations # size: LLEN. list의 크기를 반환 leftPush: LPUSH. list의 head에 값을 추가 rightPush: RPUSH. list의 tail에 값을 추가 set: LSET. 특정한 index에 값을 설정 remove: LREM. list에서 value를 count 숫자만큼 제거 leftPop: LPOP. list의 head에서 값을 제거하고 반환 rightPop: RPOP.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/java/001_facade_pattern/</link>
      <pubDate>Wed, 13 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/java/001_facade_pattern/</guid>
      <description>퍼사드 (Facade) 패턴 # 복잡한 서브 시스템 의존성을 최소화하는 방법. 클라이언트가 사용해야 하는 복잡한 서브 시스템 의존성을 간단한 인터페이스로 추상화 할 수 있다. 복잡한 디테일을 퍼사드 뒤로 숨긴다. 복잡한 서브 클래스들의 공통적인 기능을 정의하는 상위 수준의 인터페이스를 제공하는 패턴이다. 서브 클래스의 코드에 의존하는 일을 감소시켜 주고, 복잡한 소프트웨어를 간단히 사용 할 수 있게 간단한 인터페이스를 제공해준다. 서브 시스템(SubSystem)들 간의 종속성을 줄여줄 수 있으며, 퍼사드 객체를 사용하는 곳(Client)에서는 여러 서브 클래스들을 호출할 필요 없이 편리하게 사용할 수 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/001_kafka_cdc/</link>
      <pubDate>Mon, 11 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/001_kafka_cdc/</guid>
      <description>tech blog 글 읽고 정리하기 # CDC 너두 할 수 있어(feat. B2B 알림 서비스에 Kafka CDC 적용하기) # B2B 알림 서비스에 CDC를 도입을 하게 되었다.&#xA;B2B 알림 서비스 # B2B 알림 서비스 프로젝트가 무엇일까? 배민 B2C 고객 서비스에서는 알림센터라는 시스템을 통해 고객에 알림을 발송한다. 하지만, 사장님에게 발송되는 알림은 플랫폼이 부재한 관계로 카카오 알림톡으로 발송하고 있었다. 개선을 위해 알림센터를 활용해 사장님에게 전달되는 메시지를 내부 서비스를 통해 전달함으로써, 내부 서비스 활용도와 사용자 편의성을 향상시키고자 진행한 프로젝트가 &amp;lsquo;B2B 알림서비스&amp;rsquo;다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/mongodb/003_spring_data_mongodb/</link>
      <pubDate>Mon, 11 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/mongodb/003_spring_data_mongodb/</guid>
      <description>Spring data mongodb reactive # Entity # 데이터베이스에서 하나의 Document와 매칭되는 클래스 ReactiveMongoEntityTemplate, ReactiveMongoRepository 등은 데이터베이스에 요청을 보내고 그 결과를 Entity 형태로 반환한다. Collection, Document에 필요한 데이터베이스 metadata를 어노테이션 등으로 제공 ReactiveMongoTemplate # ReactiveMongoTemplate은 Spring data mongodb reactive의 추상화 클래스 Mongo 쿼리들을 Bson 형태로 넘기거나 PojoCodec, Custom codec 등을 등록하지 않아도, 메소드 체이닝을 통해서 쿼리를 수행하고 결과를 entity 객체로 받을 수 있다 ReactiveMongoOperations를 구현 MongoTemplate 생성 # MongoClient와 databaseName을 전달하여 생성 가능 spring에서는 ReactiveMongoDatabaseFactory와 MongoConverter을 주입받아 생성 ReactiveMongoOperations # ReactiveMongoTemplate의 operations를 담당하는 interface ReactiveFluentMongoOperations를 상속하고 MongoConverter 제공 MongoConverter: 주어진 Document를 Entity로 만드는 converter ReactiveMongoDatabaseFactory # getMongoDatabase: MongoDatabase를 반환 getCodecRegistry: bson의 CodecRegistry를 반환 ReactiveMongoTemplate은 ReactiveMongoDatabaseFactory의 MongoDatabase를 통해서 MongoCollection에 접근 ReactiveMongoTemplate 구현 # ReactiveMongoTemplate은 createMono 혹은 createFlux를 이용하여 MongoCollection을 획득 ReactiveMongoTemplate 구현 # createFlux를 이용하여 collectionName과 callback을 전달 callback에서 Publisher를 반환 이런 방식으로 여러 operations를 구현 MongoConverter # MongoWriter(EntityWriter를 상속), EntityReader를 구현</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/mongodb/004_object_mapping/</link>
      <pubDate>Mon, 11 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/mongodb/004_object_mapping/</guid>
      <description>Object mapping # Spring data의 object mapping # 만약 지원하는 converter가 없다면 MappingMongoConverter는 다음 과정을 거쳐서 Document를 entity로 변환 Object creation constructor, factory method 등을 이용해서 Document의 field들로 Object 생성 Property population setter, with.. 메소드 등을 이용해서 Document의 field를 Object에 주입 Object creation # 다음 순서로 체크하여 해당하는 알고리즘으로 Document를 Object로 변환 @PersistenceCreator 어노테이션을 갖는 constructor가 있다면 해당 constructor 사용 인자가 없는 constructor가 있다면 해당 constructor 사용 constructor가 정확히 하나 있다면 해당 constructor 사용 id mapping # mongodb에서 모든 document는 _id를 필요 MappingMongoConverter는 다음의 방법으로 _id를 감지 @Id가 붙어있는 필드 필드명이 id이고 @Field를 통해서 별도의 이름이 부여되지 않은 경우 id 필드가 제공되지 않는 경우, 자동으로 추가 Property population # r2dbc에서는 property가 mutable할때만 property population 적용이 가능했지만, mongodb에서는 with 메소드 지원 No-args constructor를 호출하여 텅 빈 객체를 만들고, gender를 제외한 나머지 필드는 reflection으로 진행 gender는 withGender 메소드 호출 Metadata Mapping # Entity 클래스에 annotation을 추가하여 데이터베이스와 관련된 설정들을 주입 @Id: _id에 해당하는 필드에 적용 @Document: entity class에 적용.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/mongodb/005_mongoOperations/</link>
      <pubDate>Mon, 11 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/mongodb/005_mongoOperations/</guid>
      <description>ReactiveMongoOperations # ReactiveMongoOperations # ReactiveFluentMongoOperations를 상속 ReactiveFluentMongoOperations는 여러 Operations를 상속 ReactiveFindOperation: find query와 관련된 메서드 제공 ReactiveInsertOperation: insert query와 관련된 메서드 제공 ReactiveUpdateOperation: update query와 관련된 메서드 제공 ReactiveRemoveOperation: delete query와 관련된 메서드 제공 ReactiveAggregationOperation: aggregation query와 관련된 메서드 제공 ReactiveChangeStreamOperation: watch query와 관련된 메서드 제공 ReactiveFindOperation # ReactiveFindOperation의 query 부터 시작 TerminatingFind의 count, exists, first, one, all, tail 등으로 종료 query -&amp;gt; inCollection -&amp;gt; as -&amp;gt; matching -&amp;gt; 최종 query -&amp;gt; inCollection -&amp;gt; matching -&amp;gt; 최종 query -&amp;gt; as -&amp;gt; matching -&amp;gt; 최종 query -&amp;gt; matching -&amp;gt; 최종 query -&amp;gt; 최종 ReactiveFindOperation # inCollection query를 실행할 collection 이름을 전달 제공되지 않을 경우 domain Type의 class 이름 통해 collection 이름 획득 @Document 어노테이션 통해 collection 이름 획득 as Entity를 전부 mapping하지 않고 특정 필드만 mapping 하고 싶은 경우 Entity의 일부 property만 담고 있는 subclass 또는 interface를 넘겨서 projection projection이 제공되지 않는다면 Entity에 모든 필드를 mapping matching query의 filter에 해당 Query를 전달하여 filter에 들어갈 내용을 설정 matching을 생략하면 collection 전체에 대한 요청을 보내는 것과 동일 최종 마지막으로 count, exists, first, one, all, tail 등의 연산을 선택 count: 조건에 맞는 document의 개수 반환 exists: 조건에 맞는 document 존재 여부 반환 first: 조건에 맞는 첫 번째 document 반환 one: 조건에 맞는 하나의 document 반환.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/mongodb/006_reactiveMongoRepository/</link>
      <pubDate>Mon, 11 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/mongodb/006_reactiveMongoRepository/</guid>
      <description> ReactiveMongoRepository # ReactiveMongoRepository # ReactiveSortingRepository, ReactiveQueryByExampleExecutor를 상속한 interface SimpleReactiveMongoRepository에서 구현 ReactiveMongoRepository 등록 # MongoReactiveRepositoriesAutoConfiguration가 활성화되어 있다면 SpringBootApplication 기준으로 자동으로 scan 혹은 EnableReactiveMongoRepositories를 통해서 repository scan SimpleReactiveMongoRepository # ReactiveMongoRepository를 구현 ReactiveMongoOperations를 기반으로 Mongo 쿼리를 실행하고 결과를 Entity로 mapping save # save mongoOperations의 insert 혹은 update를 이용 새로운 entity라면 insert, 아니라면 update, Id 필드가 null이라면 new saveAll concatMap을 이용하여 save를 순차적으로 실행 전부 new entity라면 bulkInsert, 아니라면 각각을 save @Transactional이 없는 점 find # findById, existsById, count 모두 ReactiveMongoOperations에서 제공하는 단축 메소드 (findById, exists, count) 사용 delete # ReactiveMongoOperations에서 제공하는 단축 메소드 (remove) 사용 References 강의 : Spring Webflux 완전 정복 : 코루틴부터 리액티브 MSA 프로젝트까지_ </description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/mongodb/007_query_method/</link>
      <pubDate>Mon, 11 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/mongodb/007_query_method/</guid>
      <description>Query method # 쿼리 메소드 (Query method) # ReactiveMongoRepository를 상속한 repository interface에 메소드를 추가 메소드의 이름을 기반으로 Query 생성 조회, 삭제 지원 @Query, @Update, @Aggregation 어노테이션을 사용해서 복잡한 쿼리 실행 가능 쿼리 메소드 - find # id 뿐만 아니라 다른 필드를 이용해서 조회 가능 first 등의 키워드를 사용해서 query에 limit 제공 가능 기존의 Entity 뿐만 아니라 Projection을 사용하여 일부 필드만 조회 가능 사용예제&#xA;findFirstByNameOrderByAgeDesc name이 “taewoo”인 row들을 찾고 age 내림차순으로 sort 하여 limit을 1로 모든 field를 조회하여 PersonDocument class로 mapping 쿼리 메소드 - delete # 다른 필드를 이용해서 삭제 가능 여러 반환 타입 지원 Long: 영향을 받은 row 수 반환 Flux: 삭제된 document 반환 사용예제</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/mongodb/001_reactive_mongodb/</link>
      <pubDate>Sun, 10 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/mongodb/001_reactive_mongodb/</guid>
      <description>Reactive MongoDB driver # MongoDB driver # MongoDB사에서 공식적인 2가지 java driver를 제공 Sync Driver Reactive Streams Driver Sync driver # 동기적으로 동작 클라이언트 요청을 보내면 응답이 돌아오기 전까지 쓰레드가 blocking 메서드가 응답 객체를 바로 반환 -&amp;gt; 직관적 쓰레드 동시성 문제 발생 가능성 Reactive Streams driver # 비동기적으로 동작 클라이언트가 요청을 보내면 쓰레드는 non-blocking 모든 응답이 publisher를 이용해서 전달되기 때문에 처리하기 어렵다. Spring reactive stack과 함께 사용되어 높은 성능, 안정성 제공 Spring Data MongoDB Reactive, REactive Streams MongoDB Driver # Mongo Reactive streams driver # MongoCollection 획득 # MongoDB의 MongoClient, MongoDatabase, MongoCollection MongoClient MongoDB 클러스터를 가리키는 객체 (MongoDatabase factory 역할) MongoDatabase Mongo의 Database를 가리킨다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/mongodb/002_mongodb_document/</link>
      <pubDate>Sun, 10 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/mongodb/002_mongodb_document/</guid>
      <description>Reactive MongoDB Document # Document # MongoCollection에 query를 실행하여 bson의 Document를 반환 bson의 Document : Map&amp;lt;String, Object&amp;gt;를 구현하고 내부에 LinkedHashMap을 저장하여 Map 메서드 override Document 예제 # collection에서 findAll query를 실행 결과를 subscribe하여 onNext로 출력 모든 결과를 찾은 후, onComplete 이벤트로 종료 MongoDB BSON 인코딩 # 첫 줄은 전체 document의 크기를 가리킨다 데이터타입, 필드명, 길이(데이터 타입에 따라 optional), 값으로 구성 BSON Codec # bson 라이브러리는 Codec을 제공 Codec을 통해서 특정 java type이 주어졌을때 어떻게 encode, docode 해야할지 지정 Default codec # MongoClientSettings에서 Default codec을 제공 Java 자체 클래스와 관련된 codec들 IterableCodecProvider: Iterable 클래스 지원 MapCodecProvider: Map 클래스 지원 ValueCodecProvider: Java에서 제공하는 클래스 지원 Jsr310CodecProvider: Instant, LocalDate, LocalDateTime 등 Date, Time 관련 클래스 지원 EnumCodecProvider: Enum 지원 Jep395RecordCodecProvider: Record 지원 Bson과 관련된 codec들 BsonValueCodecProvider: Bson 타입들을 java로 1대1 맵핑한 클래스 지원 DBRefCodecProvider: DBRef 지원 DBObjectCodecProvider: DBObject 지원 DocumentCodecProvider: Document 지원 GeoJsonCodecProvider: Geometry, LineString, MultiPoint, Point, Polygon 등의 geojson 지원 GridFSFileCodecProvider: GridFSFile 지원 JsonObjectCodecProvider: JsonObject 지원 BsonValueCodecProvider # Bson 타입들과 1 대 1 매칭 BsonNull, BsonUndefined BsonBinary BsonBoolean BsonDateTime, BsonTimestamp BsonDBPointer BsonDouble, BsonInt32, BsonInt64, BsonDecimal128 BsonMinKey, BsonMaxKey BsonJavaScript BsonObjectId BsonRegularExpression BsonString, BsonSymbol ValueCodecProvider # Java 타입들을 지원 Binary (byte[]), Byte, ByteArray (byte[]) Boolean, AtomicBoolean Date Short, Float, Double, Integer, Long, Decimal128, BigDecimal, AtomicInteger, AtomicLong MinKey, MaxKey Code (javascript code) ObjectId Pattern Character, String, Symbol Codec 예제 - StringCodec # String을 binary로 encode 만약 변환 대상이 Bson.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/batch/001_performance_improved_batch/</link>
      <pubDate>Sat, 09 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/batch/001_performance_improved_batch/</guid>
      <description>tech blog 글 읽고 정리하기 # 누구나 할 수 있는 10배 더 빠른 배치 만들기 # 우아한형제들 셀러 시스템 배치 개선 이야기 # 우아한형제들 기술 블로그의 글을 읽으면서 정리해본다.&#xA;최근 셀러시스템팀에서 하루 한 번 주기로 실행되는 배치를 최적화하는 과제를 진행한 내용에 대한 포스팅이다.&#xA;비운영 시간 데이터 # 셀러시스템에서는 가게와 업주에 대한 다양한 데이터를 관리 사장님들의 관리 사항 &amp;lsquo;가게가 운영하는지 안하는지&amp;rsquo;에 대한 정보를 유관 부서에 전달한다. &amp;lsquo;비운영시간 데이터&amp;rsquo; 실시간으로 수정되는 정보를 반영 매일 새벽에 전체 데이터를 계산하고 그 결과를 미리 갱신해둔 후, 유관부서에 전파 다양한 채널에서 입력되는 각족 운영과 휴무 데이터를 취합해서 비운영시간 데이터를 계산 위 계산된 데이터가 클라이언트까지 잘 전달될 수 있도록 각 지면에 적절한 형태로 가공하여 제공 문제상황 # 새벽에 배치 작업을 할때, 수많은 가게의 데이터를 매일 갱신하므로 배치 수행시간이 오래걸린다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/r2dbc/005_r2dbc_Metadata_mapping/</link>
      <pubDate>Sat, 09 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/r2dbc/005_r2dbc_Metadata_mapping/</guid>
      <description>05. Metadata mapping # Entity 클래스에 어노테이션을 추가 # @Id: primary key에 해당하는 필드에 적용 @Table: entity class에 적용. Table 이름을 변경 가능 @Transient: 기본적으로 모든 필드는 mapping 대상. @Transient가 붙은 필드는 mapping 에서 제외 @Column: entity의 property 필드에 적용. @Column이 붙은 필드에 대해서는 convention 기반 대신 Column에 주어진 name으로 적용 @Version: 낙관적 잠금 (Optimistic Lock)에 이용. entity가 update 될때마다 자동으로 update @PersistenceConstructor: 특정 constructor에 대해서 Object creation할 때 사용하게끔 지정.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/r2dbc/006_r2dbcEntityOperations/</link>
      <pubDate>Sat, 09 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/r2dbc/006_r2dbcEntityOperations/</guid>
      <description>06. R2dbcEntityOperations # 구조 # R2dbcEntityTemplate가 R2dbcEntityOperations를 상속한다. R2dbcEntityOperations가 FluentR2dbcOperations를 상속한다. FluentR2dbcOperations는 여러 Operations를 상속한다. ReactiveSelectOperation : select query와 관련된 메서드 제공 ReactiveInsertOperation : insert query와 관련된 메서드 제공 ReactiveUpdateOperation : update query와 관련된 메서드 제공 ReactiveDeleteOperation : delete query와 관련된 메서드 제공 ReactiveSelectOperation # ReactiveSelectOperation의 select부터 시작 TerminatingSelect의 count, exists, first, one, all 등으로 종료 구조 select -&amp;gt; from -&amp;gt; as -&amp;gt; matching -&amp;gt; 실행 select -&amp;gt; from -&amp;gt; matching -&amp;gt; 실행 select -&amp;gt; as -&amp;gt; matching -&amp;gt; 실행 select -&amp;gt; matching -&amp;gt; 실행 select -&amp;gt; -&amp;gt; 실행 ReactiveSelectOperation 사용 # from : query를 실행할 table 이름을 전달 as : Entity를 전부 mapping 하지 않고 특정 필드만 mapping 하고 싶은 경우 Entity의 일부 프로퍼티만 담고 있는 subclass(혹은 인터페이스)를 넘겨서 projection projection이 제공되지 않는다면 Entity에 모든 필드를 mapping matching : query의 where문에 해당 matching을 생략하면 table 전체에 대한 요청을 보내는 것과 동일 실행 : 마지막으로 count, exists, first, one, all 등의 연산을 선택 count: 조건에 맞는 row의 개수 반환 exists: 조건에 맞는 row 존재 여부 반환 first: 조건에 맞는 첫 번째 row 반환 one: 조건에 맞는 하나의 row 반환.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/r2dbc/007_r2dbcRepository/</link>
      <pubDate>Sat, 09 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/r2dbc/007_r2dbcRepository/</guid>
      <description>07. R2dbcRepository # R2dbcRepository 구조 # ReactiveSortingRepository와 ReactiveQueryByExampleExecutor를 상속한 interface인 SimpleR2dbcRepository에서 구현 R2dbcRepository 등록 # R2dbcRepositoriesAutoConfiguration가 활성화되어 있다면 SpringBootApplication 기준으로 자동으로 scan 혹은 EnableR2dbcRepositories를 통해서 repository scan 만약 여러 r2dbcEntityTemplate이 존재하거나 여러 데이터베이스를 사용하는 경우, basePackages, entityOperationRef 등을 통해서 다른 경로, 다른 entityTemplate 설정 가능 Repository # Spring data에서는 Repository interface를 제공 데이터에 접근하는 계층을 추상화하고 CRUD 작업, Entity mapping, SQL 쿼리 생성 등을 자동으로 수행 ReactiveCrudRepository # Spring data reactive에서는 CrudRepository의 Reactive 버전인 ReactiveCrudRepository 지원 entity의 CRUD에 집중 모든 결과값 그리고 일부 인자들이 Publisher 지원 ReactiveCrudRepository - save # saveAll은 @Transactional을 사용해서 각각의 save를 하나의 tx로 묶고 concatMap을 통해서 save를 순차적으로 수행 ReactiveCrudRepository - find # id 기반으로 하나 혹은 여러 개의 항목을 탐색하거나 존재 여부를 확인 모든 항목을 탐색하거나 모든 항목의 개수를 확인 ReactiveCrudRepository - delete # id 기반으로 하나 혹은 여러 개의 항목을 제거하거나 하나 혹은 여러 개의 entity를 기반으로 id를 추출하여 제거하거나, 모두 제거 ReactiveSortingRepository # ReactiveCrudRepository를 상속 spring data의 Sort를 기반으로 여러 항목 탐색 Sort 객체는 여러 Order 객체를 포함 이를 기반으로 query에 sort 옵션을 제공 SimpleR2dbcRepository # R2dbcRepository를 구현 R2dbcEntityOperations를 기반으로 SQL 쿼리를 실행하고 결과를 Entity로 mapping 기본적으로 모든 메소드에 @Transactional(readOnly = true) 적용 SimpleR2dbcRepository - save # new entity 확인 전략 @Id에 해당하는 필드를 확인.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/r2dbc/008_r2dbc_query_method/</link>
      <pubDate>Sat, 09 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/r2dbc/008_r2dbc_query_method/</guid>
      <description>08. R2dbc Query Method # 쿼리 메소드 (Query method) # R2dbcRepository를 상속한 repository interface에 메소드를 추가 메소드의 이름을 기반으로 Query 생성 조회, 삭제 지원 @Query 어노테이션을 사용해서 복잡한 쿼리나 update 문도 실행 가능 쿼리 메소드 - find # id 뿐만 아니라 다른 필드를 이용해서 조회 가능 first 등의 키워드를 사용해서 query에 limit 제공 가능 기존의 Entity 뿐만 아니라 Projection을 사용하여 일부 필드만 조회 가능 findFirstByNameOrderByAgeDesc name이 “taewoo”인 row들을 찾고 age 내림차순으로 sort 하여 limit을 1로 모든 field를 조회하여 PersonEntity class로 mapping 쿼리 메소드 - delete # 다른 필드를 이용해서 삭제 가능 여러 반환 타입 지원 Integer: 영향을 받은 row 수 반환 Boolean: 삭제되었는지 여부 반환 Void: 반환값보다는 completion이 중요한 경우 deleteByAgeGreaterThan age가 100 초과인 row를 찾고 삭제한 후 영향을 받은 row가 있다면 true를, 없다면 false를 반환 쿼리 메서드 시작 키워드 # find, read, get, query, search, stream find 쿼리를 실행하고 결과를 Publisher으로 반환 exists find exists 쿼리를 실행하고 결과를 Publisher으로 반환 count find count 쿼리를 실행하고 결과를 Publisher으로 반환 delete, remove delete 쿼리를 실행하고 Publisher 혹은 publisher로 삭제된 개수 반환 쿼리 메서드 제한 키워드 # First, Top 쿼리의 limit을 N으로 설정.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kotlin/005_Kotlin_extractList_Method/</link>
      <pubDate>Fri, 08 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kotlin/005_Kotlin_extractList_Method/</guid>
      <description>Kotlin에서 리스트 추출하기 : subList, slice, take, drop # 리스트의 부분 리스트 구하기 : subList(), slice(), take() # Kotlin에서는 리스트의 부분 리스트를 구하는 메서드로 여러 메서드를 제공한다. 부분 리스트를 추출하는 기능을 하는 메서드에 대해 알아보자. 원본 리스트를 변경하지 않고 추출한 새로운 리스트를 반환하는 특징이 있다. 이 메서드들은 immutable한 리스트와 mutable한 리스트 모두에서 사용할 수 있다.&#xA;subList() # 리스트의 인덱스를 기반으로 리스트의 일부분을 추출하여, 새로운 리스트를 생성한다. Java의 subList와 유사하게 시작 인덱스부터 끝 인덱스까지 요소를 추출한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kotlin/006_kotlin_nullsafe/</link>
      <pubDate>Fri, 08 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kotlin/006_kotlin_nullsafe/</guid>
      <description>tech blog 글 읽고 정리하기 # [kotlin] 널 세이프 프로그래밍 알아보기 # Null Safe 프로그래밍 # kotlin은 기본적으로 변수에 null을 할당할 수 없도록 제약하고 있다. kotlin에서 NullPointerException (NPE) 가 발생할 수 있는 원인은 다음과 같다. 명시적으로 throw NullPointerException() 을 수행한경우 &amp;lsquo;!!&amp;rsquo; 오퍼레이터를 사용한경우 다음과 같은 경우 초기화와 관련된 데이터 불일치가 발생한다. 생성자에서 사용할 수 있는 초기화 되지 않은 this가 전달되어 사용된경우 수퍼클래스 생성자가 오픈 멤버를 호출한경우, 이때 오픈멤버가 초기화 되지 않은 객체인경우 자바와 함께 사용하는 경우 참조하는 Java 대상 객체가 널인경우 자바 코드가 Generic 타입을 담는 객체에 널은 대입하고 이를 kotlin이 참조하는 경우 기본적으로 null을 변수에 담을 수 없다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/r2dbc/003_r2dbcEntityTemplate/</link>
      <pubDate>Fri, 08 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/r2dbc/003_r2dbcEntityTemplate/</guid>
      <description>03. R2dbcEntityTemplate # Entity # 데이터베이스에서 하나의 Row와 매칭되는 클래스 R2dbcEntityTemplate, R2dbcRepository 등은 데이터베이스에 요청을 보내고 그 결과를 Entity 형태로 반환 Table, Row, Column에 필요한 데이터베이스 metadat를 어노테이션으로 제공 R2dbcEntityTemplate # Spring data r2dbc의 추상화 클래스 메서드 체이닝을 통해서 쿼리를 수행하고 결과를 entity 객체로 받을 수 있다. R2dbcEntityOperations를 구현 public class R2dbcEntityTemplate implements R2dbcEntityOperations, BeanFactoryAware, ApplicationContextAware { private final DatabaseClient databaseClient; ... } R2dbcEntityTemplate 생성 # ConnectionFactory를 제공하거나 R2dbcDialect, R2dbcConverter를 제공하여 constructor로 생성 가능 R2dbcDialect : R2dbc 버전의 Dialect 확장 R2dbcEntityTemplate 빈 등록 # R2dbcDataAutoConfiguration 위 클래스를 통해서 DatabaseClient, R2dbcDialect, MappingR2dbcConverter를 주입 @AutoConfiguration(after = R2dbcAutoConfiguration.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/r2dbc/004_r2dbc_object_mapping/</link>
      <pubDate>Fri, 08 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/r2dbc/004_r2dbc_object_mapping/</guid>
      <description>04. Object mapping # Spring data의 object mapping # 만약 지원하는 converter이 없다면 MappingR2dbcConverter는 다음 과정을 거쳐서 Row를 Entity로 변환한다. Object cretion : Row의 column들로 Object 생성 Property population : direct set, setter, with..메서드 등을 이용해서 Row의 Column을 Objec에 주입 Object creation # Object creation 테스트 # R2dbcEntityTemplate의 select 호출시, R2dbcConverter를 사용하기 때문에 이를 이용해서 selet에 class를 넘기는 방식으로 테스트 PersistenceCreator constructor # @PersistenceCreator 을 갖는 constructor가 존재한다면 해당 constructor를 사용 여러개가 존재한다면 가장 마지막 @PersistenceCreator가 붙은 constructor를 사용 NoArgsConstructor, AllArgsConstructor 전부 패스 NoArgs constructor # @PersistenceCreator 을 갖는 constructor가 없는 경우 No-args constructor가 존재한다면 해당 constructor를 사용 다른 constructor 전부 패스 하나의 constructor # 오직 하나의 constructor이 존재한다면 해당 constructor 사용 2개 이상의 constructor가 있다면?</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/r2dbc/002_r2dbc_mysql/</link>
      <pubDate>Thu, 07 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/r2dbc/002_r2dbc_mysql/</guid>
      <description>02. R2dbc MySQL # R2dbc MysqlConnection # Connection을 구현한 MysqlConnection ConnectionMetadata를 구현한 MysqlConnectionMetadata Statement를 구현한 MysqlStatement MysqlConnectionFactory # Mono 형태로 포함 MysqlConnectionConfiguration을 인자로 받아서 MysqlConnectionFactory를 생성 MysqlConnectionFactory로 MysqlConnection 생성 MysqlConnection으로 MysqlStatement를 생성 MysqlConnection으로 transaction을 start, rollback, commit MysqlConnectionConfiguration # MYSQL 연결의 설정을 포함하는 객체 Builder 패턴 host, port, database, username 등 기본 설정 제공 serverZoneId 설정 MysqlConnection 생성 # Sql 준비 # Sql 실행 # ConnectionFactory의 create()를 통해서 connection 접근 connection의 createStatement를 통해서 sql 준비 result의 map으로 row에 접근하고 Person으로 변환 thenMany() chaining : 순차적으로 실행 selectPeople 결과를 아래로 전달 result의 map으로 row에 접근하고 Person으로 변환 MysqlConnection의 한계 # SQL 쿼리를 명시적으로 전달 반환된 결과를 수동으로 파싱 별도의 mapper를 만들어야하고 확장성이 떨어짐 Transaction 실행 # connection의 beginTransaction과 commitTransaction으로 transaction 시작과 commit 수행 롤백 수행 : conn.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kotlin/004_Kotlin_Scoping_Functions/</link>
      <pubDate>Tue, 05 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kotlin/004_Kotlin_Scoping_Functions/</guid>
      <description>Kotlin Scoping Functions apply vs. with, let, also, and run # apply, with, let, also, run # Kotlin의 Receiver # 객체 외부의 람다 코드 블록을 마치 해당 객체 내부에서 사용하는 것 처럼 작성할 수 있게 해주는 장치&#xA;block : T.() -&amp;gt; R 위 람다 블록은 객체 T를 receiver로 이용하여 객체 R을 반환한다.&#xA;receiver : 객체 T receiver를 사용하는 람다 : lambda with receiver block : (T) -&amp;gt; R 위의 경우 객체 T를 리시버가 아니라 람다 파라미터로 받는다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/r2dbc/001_r2dbc_intro/</link>
      <pubDate>Tue, 05 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/r2dbc/001_r2dbc_intro/</guid>
      <description>R2dbc 소개 # 왜 JDBC, JPA는 non-blocking을 지원할 수 없을까? # JDBC : 동기 blocking I/O 기반으로 설계 Socket에 대한 연결과 쿼리 실행 모두 동기 blocking으로 동작 JPA 또한 JDBC 기반 -&amp;gt; 비동기 non-blocking 지원 불가 그래서 결국, 비동기 non-blocing 기반의 API, 드라이버를 새로 만든다. R2dbc # Reactive Relational Database Connectivity 비동기 non-blocking 관계형 데이터베이스 드라이버 Reactive streams 스펙을 제공하며 Project reactor 기반으로 구현 R2dbc 지원 데이터베이스 # 공식지원 r2dbc-h2 r2dbc-mssql r2dbc-pool : Reactor pool로 커넥션 풀 제공 벤더 지원 oracle-r2dbc r2dbc-mariadb r2dbc-postgresql 커뮤니티 지원 r2dbc-mysql mirromutth 에서 2020년 5월부터 업데이트 X asyncer-io에서 RELEASE 지원 R2dbc MySQL 구조 # r2dbc-spi와 Reactor Netty 기반 Reactor Netty를 이용하여 r2dbc-spi 스펙을 구현 Reactor Netty client로 성능과 확장성 모두 제공 r2dbc-spi 스펙을 구현하여 여러 데이터베이스 시스템과 호환 R2dbc SPI # r2dbc Service Provider Interface SPI에서 제공하는 인터페이스를 구현해야한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kotlin/003_Kotlin_basic/</link>
      <pubDate>Mon, 04 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kotlin/003_Kotlin_basic/</guid>
      <description>코틀린 문법 한번에 정리하기 # 주석 정리 Variable # // top-level var x = 5 fun main() { x+= 1 println(x) val a : Int = 1 val b = 1 val c : Int c = 3 val d : Int d = 123 //val(value) : 불변(Immutable) //var(variable) : 가변(Mutable) var e : String = &amp;#34;Hello&amp;#34; e = &amp;#34;World&amp;#34; var f = 123 // f = &amp;#34;hi&amp;#34; // 컴파일 오류 타입은 변경이 불가 } Function # // 기본적인 함수 선언 스타일 fun sum(a: Int, b: Int) : Int { return a + b } // 표현식 스타일 fun sum2(a: Int, b: Int) : Int = a + b // 표현식 &amp;amp; 반환타입 생략 fun sum3(a: Int, b: Int) = a + b // 몸통이 있는 함수는 반환 타입을 제거하면 컴파일 오류 fun sum4(a: Int, b: Int) : Int { return a + b } // 반환타입이 없는 함수는 Unit을 반환한다 fun printSum(a: Int, b: Int) : Unit { println(&amp;#34;$a + $b = ${a + b}&amp;#34;) } // 디폴트 파라미터 fun greeting(message: String = &amp;#34;안녕하세요!</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/reactive_streams/002_impl1_reactor/</link>
      <pubDate>Sat, 02 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/reactive_streams/002_impl1_reactor/</guid>
      <description>Reactive Streams 구현 라이브러리 (1) Reactor # Project reactor # Pivotal 사에서 개발 Spring reactor에서 사용 Mono와 Flux publisher 제공 Project reactor - Flux # 0..n개의 item을 전달 에러가 발생하면 error signal 전달하고 종료 모든 item을 전달했다면 complete signal 전달 하고 종료 backPressure 지원 Flux 예제 # SimpleSubscriber&#xA;FluxIterable publisher Subscription : StrictSubscriber @Slf4j @RequiredArgsConstructor public class p181_SimpleSubscriber&amp;lt;T&amp;gt; implements Subscriber&amp;lt;T&amp;gt; { private final Integer count; /** * 지속적으로 요청을 하는게 아니라, 딱 한번 N개의 요청을 받고 그 이후로 값을 계속 받음 * @param s the {@link Subscription} that allows requesting data via {@link Subscription#request(long)} */ @Override public void onSubscribe(Subscription s) { log.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/reactive_streams/003_impl2_rxjava/</link>
      <pubDate>Sat, 02 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/reactive_streams/003_impl2_rxjava/</guid>
      <description>Reactive Streams 구현 라이브러리 (2) RxJava # RxJava # Netflix 사에서 개발 닷넷 프레임워크를 지원하는 Reactive Extensions를 포팅 Flowable, Observable, Single, Maybe, Completable, publisher 제공 RxJava - Flowable # 0..n개의 item을 전달 에러가 발생하면 error signal 전달 하고 종료 모든 item을 전달했다면 complete signal 전달하고 종료 backPressure 지원 Reactor의 Flux와 유사 Flowable 예제 # @Slf4j public class p199_FlowableExample { public static void main(String[] args) { log.info(&amp;#34;start main&amp;#34;); getItems() .subscribe(new p181_SimpleSubscriber&amp;lt;&amp;gt;(Integer.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/reactive_streams/004_impl3_munity/</link>
      <pubDate>Sat, 02 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/reactive_streams/004_impl3_munity/</guid>
      <description>Reactive Streams 구현 라이브러리 (3) Munity # Mutiny # Hibernate reactive에서 비동기 라이브러리로 제공 Multi, Uni publisher 제공 Mutiny - Multi # 0..n개의 item을 전달 에러가 발생하면 error signal 전달 하고 종료 모든 item을 전달했다면 complete signal 전달하고 종료 backPressure 지원 Reactor의 flux와 유사 Multi 예제 # @Slf4j public class p218_MultiExample { public static void main(String[] args) { getItems() .subscribe() // subscribe 동시에 넘길 수 없음, subscribe() 호출 후 아래 호출 필요 .</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/redis/001_redis_datastructure/</link>
      <pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/redis/001_redis_datastructure/</guid>
      <description>레디스 자료구조 활용사례 # 리더보드 # 경쟁자들의 순위와 현재 점수를 보여주는 순위표를 의미한다. 스코어로 정렬되어 상위 경쟁자의 순위를 보여준다.&#xA;절대적 리더보드 서비스의 모든 유저를 정렬시켜 상위권의 목록만을 표시&#xA;상대적 리더보드 사용자의 스코어를 기반으로 그들을 다른 사용자와 비교해 순위를 결정 ex) 유저와 인접해있는 경쟁자들의 스코어를 보여주는 리더보드, 특정 그룹 내에서의 순위를 보여주는 리더보드, 주간 리더보드&#xA;리더보드는 기본적으로 사용자의 스코어를 기반으로 데이터를 정렬하는 서비스이기 때문에 사용자의 증가에 따라 가공해야할 데이터가 몇 배로 증가한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/redis/002_redis_cache/</link>
      <pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/redis/002_redis_cache/</guid>
      <description>레디스를 캐시로 사용하기 # [캐시란?] # 데이터의 원본보다 더 빠르고 효율적으로 액세스할 수 있는 임시 데이터 저장소를 의미한다.&#xA;[캐시로서의 레디스] # 레디스는 자체적으로 고가용성 기능을 가지고있다. 일부 캐싱 전략에서는 캐시에 접근할 수 없게 되면 이는 곧바로 서비스 장애로 이어질 수 있따. 캐시 저장소도 일반적인 데이터 저장소와 같이 안정적으로 운영될 수 있는 조건을 갖추는 것이 좋다. 레디스의 센티널, 클러스터 기능을 사용하면 마스터 노드의 장애를 자동으로 감지해 페일오버(Failover; 장애대비)를 발생시키기 때문에, 운영자의 개입 없이 캐시는 정상으로 유지될 수 있어 가용성이 높아진다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kotlin/002_Functional_Programming_Example/</link>
      <pubDate>Sun, 26 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kotlin/002_Functional_Programming_Example/</guid>
      <description>코틀린으로 함수형 프로그래밍 시작하기 # [고차함수 : 함수를 함수에 넘기기] # 함수형 프로그램을 작성할때 기본이 되는 몇가지 주제&#xA;함수도 값이다. 함수를 변수에 대입하거나 데이터 구조에 저장하거나 함수의 인자로 넘길 수 있다. 고차함수란? 다른 함수를 인자로 받는 함수&#xA;고차함수 예제 어떤 수의 절댓값과 다른 수의 계승(팩토리얼; factorial)을 출력하는 프로그램&#xA;루프를 함수적으로 작성하는 방법 n의 계승을 계산하는 함수를 추가한다. 재귀(recursion)를 통해 순수 함수로 루프를 작성할 수 있다. fun factorial(i: Int): Int { fun go(n: Int, acc: Int): Int = // &amp;lt;1&amp;gt; if (n &amp;lt;= 0) acc // 루프를 종료시키려면 재귀 호출을 하지 않고, 값을 반환한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kotlin/001_Functional_Programming/</link>
      <pubDate>Wed, 22 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kotlin/001_Functional_Programming/</guid>
      <description>함수형 프로그래밍이란? # 명령어 스타일 (imperative style) # 컴퓨터에게 정해진 명령 또는 지시를 하나하나 내림으로써 각 명령 단계마다 시스템의 상태를 바꾼다. 처음에는 단순화하려는 의도나, 시스템이 커질수록 복잡해지며, 그 결과 코드를 더이상 유지보수할 수 없게 되고, 테스트 하기 어려워지며 코드를 추론하는데에 어려워진다. 함수형 프로그래밍 (FP, Functional Programming) # 위 명령어 스타일의 대안으로, &amp;lsquo;부수 효과&amp;rsquo;를 완전히 없애는 개념이다. 함수형 프로그래밍의 전제는, 순수 함수를 통해 프로그램을 구성한다는 것이다. 순수 함수 : 아무 부수 효과가 없는 함수 부수 효과란?</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/reactive_streams/001_reactive_streams_component/</link>
      <pubDate>Sun, 11 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/reactive_streams/001_reactive_streams_component/</guid>
      <description>리액티브 스트림즈란? # 리액티브한 코드 작성을 위한 구성을 도와주는 리액티브 라이브러리가 있다. 이 리액티브 라이브러리를 어떻게 구현해야할지 정의해놓은 별도의 표준 사양을 리액티브 스트림즈(Reactive Streams)라고 한다.&#xA;리액티브 스트림즈는 &amp;lsquo;데이터 스트림을 Non-Blocking이면서 비동기적인 방식으로 처리하기 위한 리액티브 라이브러리 표준 사양&amp;rsquo;이라고 표현할 수 있다. 이를 구현한 구현체로는 RxJava, Reactor, Akka Streams, Java 9 Flow API 등이 있고, 그 중에 Spring framework와 가장 궁합이 잘 맞는 구현체는 Reactor이다.&#xA;리액티브 구성요소 # 리액티브 스트림즈를 통해 구현해야 되는 API 컴포넌트에는 Publisher, Subscriber, Subscription, Processor 가 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/algorithm/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/algorithm/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/data_structure/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/data_structure/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/ddd/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/ddd/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/docker/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/docker/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/jenkins/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/jenkins/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/jpa/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/jpa/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/linux/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/linux/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/mvc/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/mvc/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/mysql/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/mysql/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/network/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/network/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/oracle/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/oracle/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/security/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/security/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/servlet/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/servlet/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/spring/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/spring/000_sample/</guid>
      <description>sample</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/webflux/000_sample/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/webflux/000_sample/</guid>
      <description>sample</description>
    </item>
  </channel>
</rss>
