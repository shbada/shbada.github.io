<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kafka on TIL</title>
    <link>https://example.com/tags/kafka/</link>
    <description>Recent content in kafka on TIL</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 27 Jan 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://example.com/tags/kafka/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/006_replication/</link>
      <pubDate>Sat, 27 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/006_replication/</guid>
      <description>강의 메모 # 브로커의 복제(Replication) # 브로커의 역할 - 복제(Replication) # 데이터 복제 : 클러스터로 묶인 브로커 중 일부에 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함이다. 토픽을 생성할때 파티션의 복제 개수(replication factor) 같이 설정 - default는 브로커에 설정된 옵션 값으로 설정&#xA;복제 개수의 최솟값은 1(복제 없음) 최댓값은 브로커 개수만큼 설정하여 사용 가능 복제된 파티션의 구성 : 리더(leader), 팔로워(follower)&#xA;리더 : 프로듀서, 컨슈머와 직접 통신하는 파티션 팔로워 : 리더의 데이터가 추가되면 복제해가는 역할 복제 과정 : 팔로워 파티션들은 리더 파티션의 오프셋을 확인하여 현재 자신이 가지고있는 오프셋과 차이가 나는 경우 리더 파티션으로부터 데이터를 가져와서 자신의 파티션에 저장한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/007_isr/</link>
      <pubDate>Sat, 27 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/007_isr/</guid>
      <description>강의 메모 # ISR (In-Sync-Replicas) # ISR (In-Sync-Replicas) # 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태를 뜻한다. 리더 파티션의 오프셋이 0~3까지 있을때 팔로워 파티션도 0~3이 있다. (동기화 완료 - 리더 파티션의 모든 데이터가 팔로워 파티션에 복제가 완료되었다 라는 뜻)&#xA;unclean.leader.election.enable # 모두 복제되지 않은 상황이고, 이렇게 싱크가 되지 않은 팔로워 파티션이 리더 파티션으로 선출되면 데이터가 유실될 수 있다. 유실이 발생하더라도 서비스를 중단하지 않고 지속적으로 토픽을 사용하고 싶으면 ISR이 아닌 팔로워 파티션을 리더로 선출하도록 설정할 수 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/004_kafka_broker/</link>
      <pubDate>Sun, 21 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/004_kafka_broker/</guid>
      <description>강의 메모 # 카프카 브로커, 클러스터, 주키퍼 # 주키퍼 # 카프카 클러스터를 운영하기 위해 반드시 필요한 애플리케이션 카프카 2.0 버전 까지는 반드시 필요했지만 카프카 3.0부터는 주키퍼가 없더라도 운영됨 아직까지는 주키퍼를 완벽하게 대체하지 못하므로 주키퍼가 있는 카프카 클러스터 운영 기업이 많음&#xA;1개의 브로커는 하나의 서버나 인스턴스에서 동작 브로커 3개가 있는 모습&#xA;브로커 # 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션 하나의 서버에는 하나의 카프카 브로커 프로세스가 실행됨 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영한다 카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산 저장하고 복제하는 역할을 수행한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/005_broker_log_segment/</link>
      <pubDate>Sun, 21 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/005_broker_log_segment/</guid>
      <description>강의 메모 # 로그와 세그먼트 # log.segment.bytes : 바이트 단위의 최대 세그먼트 크기 지정 (기본 값은 1GB)&#xA;log.roll.ms(hours) : 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기 (기본값은 7일)&#xA;프로듀서가 데이터를 전송하면 active 되어있는 .log 파일에 offset 22번으로 들어간다. (FIFO)&#xA;가장 최초의 offset 번호가 파일 이름이 된다&#xA;가장 마지막 세그먼트 파일을 active segment라고 한다.&#xA;브로커의 삭제 대상에서 포함되지 않는다. retention 옵션에 ㄸ라 삭제 대상으로 지정된다. 세그먼트와 삭제 주기 (cleanup.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/003_transactional_outbox_pattern/</link>
      <pubDate>Sat, 20 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/003_transactional_outbox_pattern/</guid>
      <description>기술 블로그 정리 # Transactional Outbox 패턴이 등장하게된 상황 # Event Driven Architecture &amp;gt; 메시지 발행의 신뢰성 보장 패턴 Event driven ARchitecture : Message Broker를 이용해 다양한 메시지(이벤트)를 publish(발행) 하고, 그에 연관된 작업을 비동기적으로 처리하여 시스템을 통합 DB 트랜잭션을 실행한 뒤, 연관 메시지를 Message Broker에 publish 하게 되는데, 메시지 publish가 반드시 완료되어야하는 경우가 있다. 예시) 리디 주문 기능; 주문이 발생하면 사용한 캐시&amp;amp;포인트 금액을 차감하고 상품을 지급하며 주문 완료로 상태를 바꾸는 DB 트랜잭션이 발생 -&amp;gt; Message Broker에 주문 완료 메시지를 publish 이 경우, DB와 Message Broker의 트랜잭션 원자성 보장이 어렵다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/002_kafka_intro/</link>
      <pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/002_kafka_intro/</guid>
      <description>강의 메모 # 아파치 카프카의 탄생과 기본 구조 # 카프카의 탄생&#xA;각각의 애플리케이션끼리 연결하여 데이터를 처리하는게 아닌, 한 곳에 모아 처리할 수 있도록 중앙집중화했다. 메시지 큐 구조를 그대로 살린 카프카 내부 구조 # 카프카 내부에 데이터가 저장되는 파티션의 동작은 FIFO(First In First Out) 방식의 큐 자료구조와 유사하다. 큐에 데이터를 보내는 것이 프로듀서 큐에서 데이터를 가져가는 것이 컨슈머 적재된 데이터를 하나하나 가져가더라도 파티션 내의 데이터는 삭제되지 않는다. 데이터를 읽는것 : 커밋 (데이터를 어디까지 읽었는지를 기록) 카프카가 데이터 파이프라인으로 적합한 4가지 이유 # 1.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/kafka/001_kafka_cdc/</link>
      <pubDate>Mon, 11 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/kafka/001_kafka_cdc/</guid>
      <description>tech blog 글 읽고 정리하기 # CDC 너두 할 수 있어(feat. B2B 알림 서비스에 Kafka CDC 적용하기) # B2B 알림 서비스에 CDC를 도입을 하게 되었다.&#xA;B2B 알림 서비스 # B2B 알림 서비스 프로젝트가 무엇일까? 배민 B2C 고객 서비스에서는 알림센터라는 시스템을 통해 고객에 알림을 발송한다. 하지만, 사장님에게 발송되는 알림은 플랫폼이 부재한 관계로 카카오 알림톡으로 발송하고 있었다. 개선을 위해 알림센터를 활용해 사장님에게 전달되는 메시지를 내부 서비스를 통해 전달함으로써, 내부 서비스 활용도와 사용자 편의성을 향상시키고자 진행한 프로젝트가 &amp;lsquo;B2B 알림서비스&amp;rsquo;다.</description>
    </item>
  </channel>
</rss>
