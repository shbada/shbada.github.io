<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>java on TIL</title>
    <link>https://example.com/tags/java/</link>
    <description>Recent content in java on TIL</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 13 Feb 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://example.com/tags/java/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/042_threadpool/</link>
      <pubDate>Tue, 13 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/042_threadpool/</guid>
      <description>강의 메모 - 스레드 풀 이해와 구현 # 개요 # 스레드 풀 (Thread Pool) 은 다수의 스레드를 미리 생성하고 관리하여 작업을 효율적으로 처리하는 디자인 패턴이다 자바에서는 스레드 풀을 사용할 수 있는 Executor 프레임워크를 제공하고 있다 스레드 풀은 왜 필요한가 # 스레드 풀을 구현할 때 필요한 핵심 요소는 무엇인가 # 스레드 풀 구조 # 작업을 스레드 풀에 등록하면 스레드 풀은 큐에 작업을 저장한다 미리 생성된 스레드는 큐로부터 작업을 하나씩 가져가고 작업을 진행한다 작업을 완료하면 다음 작업을 할당받기 위해 시도한다 스레드가 할당 받을 작업이 없으면 요청이 들어올 때 까지 계속 대기한다 (wait) 할당 받을 작업이 올때까지 스레드가 모두 작업 중이고 큐에 작업이 존재할 경우 스레드를 추가 생성한다 가용할 수 있는 최대 스레드 개수만큼 생성 가능하기 때문에 추가 생성할 수 있음 일반적으로 스레드 생성 개수는 기본 개수와 최대 개수로 제한을 둔다 만약 Queue에 계속해서 작업이 들어오는데 Thread가 모두 working 중이면 Queue에 작업이 계속 쌓이게되어 쓰레드 풀이 예외를 발생시킬 수 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/043_executor/</link>
      <pubDate>Tue, 13 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/043_executor/</guid>
      <description>강의 메모 - Executor # 개요 # 자바 Executor Framework 는 자바의 java.util.concurrent 패키지에 포함된 스레드 관리와 병렬 처리를 위한 고급 기능들을 제공하는 포괄적인 라이브러리이다 Executor Framework 는 복잡한 스레드 생성, 관리, 동기화 등의 작업을 단순화하고 성능을 향상시키기 위한 다양한 클래스와 인터페이스를 제공하고 있다 Executor Framework # Executor # Executor Framework 의 핵심 인터페이스로서 단일 메서드 execute(Runnable command)를 정의하고 있으며 작업을 제출하면 Executor 구현체가 적절한 스레드를 생성하고 작업을 실행한다 ExecutorService # Executor 의 확장 버전으로서 작업의 제출과 스레드 풀의 종료를 관리하기 위한 메서드들을 추가로 제공한다 ScheduledExecutorService # ExecutorService 의 확장으로 특정 시간 또는 주기적으로 작업을 실행할 수 있도록 스케줄링하는 메서드들을 제공한다 Executor 구현체 # Executor 의 구현체로는 ThreadPoolExecutor,ScheduledThreadPoolExecutor 등이 있다 이들은 스레드 풀의 생성, 관리, 작업 큐, 스레드 생성 및 삭제 정책 등을 다양한 설정으로 제어할 수 있는 강력한 도구이다 Executor # 제출(Submit)된 Runnable 작업을 실행(Execute) 하는 객체 Executor 인터페이스는 각 작업의 실행(실행방법, 스레드 사용, 스케줄링 등의 세부 사항) 과 작업의 제출을 분리하는 방법을 제공한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/038_cas_algorithm/</link>
      <pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/038_cas_algorithm/</guid>
      <description>강의 메모 - CAS (Compare and Swap) 이해와 활용 - 1,2 # 개요 # CAS(Compare and Swap, 비교 후 치환) 는 멀티 스레드 환경에서 스레드 간의 경쟁 조건을 방지하고 락을 사용하지 않고도 공유 변수의 값을 원자적으로 변경하는 방법을 제공한다 CAS 는 CPU 캐시와 메인메모리의 두 값을 비교하고 그 값이 동일할 경우 새로운 값으로 교체하는 동기화 연산으로 여러 스레드가 공유하는 메모리 영역을 보호하는 데 사용된다 CAS 는 락 기반의 동기화보다 경량화되어 있으며 락을 사용하지 않기 때문에 대기하지 않는 넌블록킹 실행이 가능하고 경쟁 조건과 데드락을 피할 수 있다 CAS는 조건에 따라 실패하고 다시 시도해야 할 수 있기 때문에 동시적으로 접근하는 요청의 수가 많은 경쟁 조건일 경우 효율성이 저하될 수 있다 CAS는 주로 하드웨어 수준(CPU) 에서 지원되는 연산이며 Java에서는 java.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/039_atomic/</link>
      <pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/039_atomic/</guid>
      <description>강의 메모 - Atomic Variables - 단일연산변수 - 1,2 # 개요 # 단일연산변수는 락을 사용하지 않고도 여러 스레드 간에 안전하게 값을 공유하고 동기화하는 데 사용되며 기본적으로 volatile 의 속성을 가지고 있다 단일연산변수는 원자적인(read-modify-write) 연산을 지원하여 내부적으로 Compare and Swap (CAS) 연산을 사용하여 데이터의 일관성과 안정성을 유지한다 단일연산변수는 간단한 연산의 경우 락을 사용하는 것보다 월등히 빠른 성능을 보여 주지만 연산이 복잡거나 시간이 오래 걸리는 작업은 락을 사용하는 것보다 오버헤드가 커질 수 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/040_countDownLatch/</link>
      <pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/040_countDownLatch/</guid>
      <description>강의 메모 - CountDownLatch # 개요 # 하나 이상의 스레드가 다른 스레드에서 수행되는 일련의 작업이 완료될 때까지 기다릴 수 있게 해주는 동기화 보조 도구이다 CountDownLatch는 주어진 카운트로 초기화되고 await 메서드는 현재 카운트가 countDown 메서드의 호출로 인해 0이 될 때까지 블록되며 그 이후에 모든 대기 중인 스레드가 해제되고 await() 이후 처리가 이루어진다 CountDownLatch 은 일회성으로 처리된다. 즉 카운트를 재 설정할 수 없다( 카운트를 재설정하는 버전이 필요한 경우 CyclicBarrier 를 사용한다) 한 스레드가 여러 번 countDown() 을 호출해도 된다 사용 용도 # 여러 개의 스레드가 병렬로 실행되는 경우 특정 작업이 시작되거나 완료될 때까지 다른 스레드들이 기다리도록 할 수 있다 여러 스레드가 초기화 작업을 마칠 때까지 기다렸다가 모든 스레드가 완료되면 마무리 작업을 수행할 수 있습니다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/041_cyclicBarrier/</link>
      <pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/041_cyclicBarrier/</guid>
      <description>강의 메모 - CyclicBarrier # 개요 # CyclicBarrier 는 공통된 장벽 지점에 도달할 때까지 일련의 스레드가 서로 기다리도록 하는 동기화 보조 도구이다 각 스레드끼리 cycleBarrier을 공유하고 각각 쓰레드에서 await()을 호출해야한다. countDownLatch는 작업 기준이라면, CyclicBarrier는 쓰레드 기준 CyclicBarrier 는 대기 중인 스레드가 해제된 후에 재 사용할 수 있기 때문에 순환 장벽이라고 부른다 CyclicBarrier는 옵션으로 Runnable 명령을 지원하는데 이 명령은 마지막 스레드가 도착한 후에 각 장벽 지점마다 한 번씩 실행되는 장벽액션(barrierAction) 역할을 수행한다 이 Runnable 은 스레드가 장벽 이후 실행을 계속하기 전에 공유 상태를 업데이트하는 데 유용하다 각 하나의 쓰레드가 await()을 호출해야함 각 쓰레드가 await()을 호출하게 되면 -1씩 되어 0이 되는 시점이 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/036_reentrantReadWriteLock/</link>
      <pubDate>Wed, 07 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/036_reentrantReadWriteLock/</guid>
      <description>강의 메모 - ReentrantLock # 개요 # ReadWriteLock 은 읽기 작업과 쓰기 작업을 위해 연관된 두 개의 락(읽기 락, 쓰기 락)을 유지하는 인터페이스이다 일반적으로 락은 데이터를 조작하는 하나의 스레드의 임계영역을 보호하는 장치이며 데이터를 읽는 작업만 실행되는 영역은 여러 스레드가 동시에 접근해도 동시성 문제가 발생하지 않는다 읽기 작업이 많고 쓰기 작업이 적은 영역을 효율적으로 처리하기 위해 다수의 읽기와 하나의 쓰기를 읽기락과 쓰기락으로 구분해서 락을 운용하는 것이 필요하다 특징 # 성능 개선</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/037_condition/</link>
      <pubDate>Wed, 07 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/037_condition/</guid>
      <description>강의 메모 - Condition # 개요 # Condition 은 조건 변수 또는 조건 큐로 알려진 객체로서 Lock 과 결합하여 객체 당 여러 개의 Wait Queue 을 가지는 효과를 제공한다 Lock 이 synchronized 메서드와 문장의 사용을 대체하는 것처럼 Condition은 Object 모니터 메서드 (wait, notify and notifyAll) 의 사용을 대체하며 Lock 에 바인딩된다 Condition 은 한 스레드가 다른 스레드로부터 어떤 상태 조건이 참이 될 수 있다는 통지를 받을 때까지 실행을 중단하도록 하는 수단을 제공한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/035_reentrantLock/</link>
      <pubDate>Tue, 30 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/035_reentrantLock/</guid>
      <description>강의 메모 - ReentrantLock # 개요 # ReentrantLock 은 락 획득 과정에서 스레드가 대기하거나 차단하지 않는 API 를 지원하여 유연한 코드 구현이 가능하다 tryLock() 락을 획득한 경우와 획득하지 못한 경우를 별도로 처리해야하는 상황에서 사용 finally에서 lock 해제 필수 lockInterruptibly() 인터럽트의 명령을 받으면 catch 문 수행 ReentrantLock # ReentrantLock() // ReentrantLock(false)를 사용하는 것과 동일하며 내부적으로 NonfairSync 클래스 객체인 불공정성 락을 생성한다 ReentrantLock(boolean fair) //주어진 공정성 정책으로 인스턴스를 생성한다. 공정성 락을 사용해야 하는 경우 fair 는 true 이며 내부적으로 FairSync 클래스 객체를 생성한다 // 현재 스레드가 이 락을 보유한 횟수를 반환하며이 락을 보유하지 않은 경우에는 0 을 반환한다 int getHoldCount() // 현재 스레드가 이 락을 보유하고 있는지 확인한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/034_lock_ReentrantLock/</link>
      <pubDate>Mon, 29 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/034_lock_ReentrantLock/</guid>
      <description>강의 메모 - Lock &amp;amp; ReentrantLock - 1,2 # 개요 # Lock 구현은 synchronized 구문과 마찬가지로 상호배제와 가시성 기능을 가진 동기화 기법이며 synchronized 보다 더 확장된 락 작업을 제공한다&#xA;Lock 구현은 락을 획득 시 블록되지 않는 비 차단 시도(tryLock()), 인터럽트가 가능한 방식으로 락을 획득하는 시도(lockInterruptibly) 및 시간 제한을 둔 방식으로 락을 획득하는 시도(tryLock(long, TimeUnit))와 같은 추가 기능을 제공한다&#xA;synchronized 사용은 락 획득과 락 해제가 블록 구조화된 방식으로 발생하도록 강제한다</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/032_volatile/</link>
      <pubDate>Sun, 28 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/032_volatile/</guid>
      <description>강의 메모 - volatile # 개요 # volatile 은 변수의 가시성과 연산의 순서를 제어하기 위해 사용하는 키워드로서 스레드 간의 데이터 일관성과 가시성을 보장하는 역할을 한다 가시성 보장 : 모든 쓰레드가 동일한 값을 보는것 CPU 캐시 메모리와 메인 메모리 # 현대 컴퓨터는 거의 대부분 2개 이상의 CPU가 장착되어 있으며 각 코어에는 레지스터와 캐시메모리가 존재한다 CPU 캐시 메모리는 CPU 레지스터와 메인 메모리 사이에서 데이터 흐름을 최적화하고 성능을 향상시키기 위해 사용되는 고속 메모리이다 CPU 는 값을 읽어올 때 우선 캐시에 해당 값이 있는지 확인하고 없는 경우에만 메인 메모리에서 읽어오는 특성을 가진다 CPU 가 데이터 처리를 위해 메인 메모리로 접근 할 때 다음과 같은 순서로 진행한다</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/033_deadlock/</link>
      <pubDate>Sun, 28 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/033_deadlock/</guid>
      <description>강의 메모 - Deadlock - 교착상태 - 1,2 # 개요 # DeadLock(교착상태) 이란 프로세스나 스레드들이 서로가 소유하고 있는 자원을 기다리며 무한히 대기하고 있는 상태를 말한다 교착상태에서는 아무런 진전도 이루어지지 않아 작업이 진행되지 않는 문제가 발생한다 DeadLock 은 동일한 환경과 코드에서 발생할 수도 있고 발생하지 않을 수도 있다 완전한 해결은 없고, &amp;lsquo;예방&amp;rsquo;과 &amp;lsquo;최소화&amp;rsquo;하는 느낌 - 예측이 어려운 상황 데드락 발생 조건 # 데드락은 다음의 네 가지 필요 조건을 동시에 만족할 때 발생한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/031_wait_notify/</link>
      <pubDate>Sat, 27 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/031_wait_notify/</guid>
      <description>강의 메모 - 스레드 간 협력 - wait() &amp;amp; notify() # 개요 # wait(), notify(), notifyAll() 은 모니터 객체의 조건변수와 함께 사용해서 동기화를 구현할 수 있는 동기화 메커니즘이라 할 수 있다. wait(), notify(), notifyAll() 은 뮤텍스(상호배제) 동기화 기법으로 충족되지 않는 동기화 문제를 해결할 수 있는 협력에 의한 동기화 장치이다 wait(), notify(), notifyAll() 은 반드시 synchronized 블록 안에서만 사용해야 하며 이는 스레드가 모니터 락을 확보한 상태에서 이 API 들이 작동한다는 것을 의미한다 모니터 락 안에서 사용해야한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/030_synchronized_etc/</link>
      <pubDate>Thu, 25 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/030_synchronized_etc/</guid>
      <description>강의 메모 - synchronized 특성 # 재진입성 # 모니터 내에서 이미 synchronized 영역에 들어간 스레드가 다시 같은 모니터 영역으로 들어갈 수 있는데, 이를 &amp;ldquo;모니터 재진입&amp;quot;이라고 한다 재진입 가능하다는 것은 락의 획득이 호출 단위가 아닌 스레드 단위로 일어난다는 것을 의미하며 이미 락을 획득한 스레드는 같은 락을 얻기 위해 대기할 필요 없이 synchronized 블록을 만났을 때 같은 락을 확보하고 진입한다 같은 모니터라면 대기/경쟁 없이 바로 진입 가능 (스레드 단위) 상속하게 되면 자식은 부모의 락과 동일한 락을 가지게 된다 자식 클래스에서 method() 실행됨 부모클래스의 method() 실행 서로 모니터가 동일하므로 재진입이 가능한것 동기화 된 메서드에서 다른 동기화 된 메서드를 호출하는 경우 이미 락(lock)을 가지고 있는 스레드가 같은 락을 확보하고 재진입 시 데드락이 발생하지 않고 정상적으로 진행할 수 있게 된다 가시성 # synchronized 는 가시성을 지원한다 가시성이란 한 스레드가 공유자원을 수정하거나 쓰기 작업을 했을 때 다른 스레드가 수정한 내용이 보이는 것을 말한다 CPU 특성상 cache memory를 가진다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/029_method_synchronized/</link>
      <pubDate>Mon, 22 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/029_method_synchronized/</guid>
      <description>강의 메모 - synchronized 메서드 동기화 # 인스턴스 메서드 동기화 (synchronized method) # 인스턴스 단위로 모니터가 동작하며 동일한 인스턴스 안에서 synchronized 가 적용된 곳은 하나의 락을 공유한다 인스턴스가 여러개일 경우 인스턴스별로 모니터 객체를 가지므로 스레드는 모니터 별로 락을 획득해서 동기화 영역에 진입하고 빠져 나올 때 락을 해제 할 수 있다 MyClass 내부적으로 가지고있는 객체 타입 : this (=모니터) 위 두 메서드의 모니터가 동일하다. 정적 메서드 동기화 (static synchronized method) # 클래스 단위로 모니터가 동작하며 synchronized 가 적용된 곳은 하나의 락을 공유한다 인스턴스와는 별개의 모니터를 가지고 임계 영역을 동기화 하기 때문에 인스턴스 단위로 메서드를 호출할지라도 락은 클래스 단위로 스레드간 공유된다 클래스는 메모리에 오직 하나만 존재하므로 하나의 모니터를 공유해서 동기화 하고자 할 때 사용 할 수 있다 정적메서드이기 때문에 클래스 타입으로 주어짐 -&amp;gt; MyCalss = monitor 인스턴스 메서드 동기화 (synchronized method) + 정적 메서드 동기화 (static synchronized method) # synchronized method 와 static synchronized method 가 혼용되었을 경우는 각 모니터별로 동기화를 진행한다 모니터가 섞여 있기 때문에 동기화가 의도한대로 정확하게 동작하는지 주의가 필요하다 위 1, 2 메서드의 모니터는 같다 위 3,4 메서드의 모니터는 같다 References 강의 : https://www.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/027_spin_lock/</link>
      <pubDate>Sat, 20 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/027_spin_lock/</guid>
      <description>강의 메모 - SpinLock &amp;amp; Busy Waiting # 개요 # 스핀락(SpinLock)은 뮤텍스나 세마포어와 같은 동기화 기법의 일종으로, 기다리지 않고 스레드가 임계영역을 사용할 수 있을 때까지 계속 반복하여 검사하는 동기화 메커니즘이다 작동방식 # 스레드가 공유 자원에 접근하려고 할 때, 먼저 스핀락을 시도한다 test_and_set() 함수가 이전 락 값인 0 을 반환하면 아직 락이 잠기지 않았다는 것을 의미하며 while 루프를 빠져 나온다 스레드는 스핀락을 얻고 해당 자원을 사용한다 그러나 이전 락 값이 1이면 이미 다른 스레드에 의해 잠긴 것을 의미하며 스핀락을 얻을 때까지 계속해서 반복적으로 검사를 수행한다 스레드가 자원 사용이 끝나면 lock 을 0 으로 변경해서 스핀락을 해제한다 Busy Waiting (바쁜 대기) # Busy waiting은 스레드가 어떤 조건이 만족될 때까지 계속해서 반복적으로 검사하는 것을 말한다 스레드가 특정 조건을 기다리는 동안 아무런 유용한 작업을 수행하지 않고, 무한 반복 루프를 돌며 CPU 자원을 계속 사용하는 것을 의미한다 스핀락은 이러한 busy waiting을 사용하는 동기화 기법 중 하나이다 스핀락 자바 구현 # 임계영역을 수행하고 unlock() 호출 스핀락의 장점, 단점 # 장점</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/028_synchronized_basic/</link>
      <pubDate>Sat, 20 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/028_synchronized_basic/</guid>
      <description>강의 메모 - synchronized 기본 # 개요 # 자바는 단일 연산 특성을 보장하기 위해 synchronized 키워드를 제공하고 있으며 synchronized 구문을 통해 모니터 영역을 동기화 할수 있다 synchronized 는 명시적으로 락을 구현하는 것이 아닌 자바에 내장된 락으로서 이를 암묵적인 락(Intrinsic Lock) 혹은 모니터락 (Monitor Lock) 이라고 한다 자바에 내장된 락 (암묵적인 락, 모니터락) synchronized 은 동일한 모니터를 가진 객체에 대해 오직 하나의 스레드만 임계영역에 접근할 수 있도록 보장하며 모니터의 조건 변수를 통해 스레드간 협력으로 동기화를 보장해 준다 synchronized 가 적용된 한 개의 메서드만 호출해도 같은 모니터의 모든 synchronized 메서드까지 락에 잠기게 되어 락이 해제될 때 까지는 접근이 안되는 특징을 가지고 있다 앞에서 배운 &amp;lsquo;모니터&amp;rsquo;를 synchronized 키워드에 넣었으므로 모니터 장점을 가지고있음 락은 스레드가 synchronized 블록에 들어가기 전에 자동 확보되며 정상적이든 비정상적이든 예외가 발생해서든 해당 블록을 벗어날 때 자동으로 해제된다 lock은 자동 확보/자동 해제 synchronized 는 모니터 락을 사용하여 동기화 할 수 있는 4가지 방법을 제공한다 # method synchronized method static synchronized method block synchronized block static synchronized method 원리는 동일 세부적으로는 인스턴스냐, 클래스냐 (method, block 각각 안에서도 세부적으로 나누는 기준) A 메서드 안에 4가지(위 구분 4가지)를 정의했다고 해보자.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/026_monitor/</link>
      <pubDate>Fri, 19 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/026_monitor/</guid>
      <description>강의 메모 - Monitor - 모니터 -1,2 # 개요 # 자바가 동기화를 지원하기 위해 사용하는 메커니즘은 모니터(Monitor) 이며 뮤텍스나 세마포어보다 더 고수준의 동기화 기법이다 뮤텍스, 세마포어를 좀더 추상화한것 모든 자바 객체는 기본적으로 모니터를 가지며 여러 스레드가 객체의 임계 영역(critical section)에 진입하려고 할 때 JVM 은 모니터를 사용하여 스레드 간 동기화를 제공한다 자바의 모니터는 상호 배제(Mutual Exclusion) 및 협력(Cooperation)이라는 두 가지 동기화 기능을 제공하고 있으며 이를 위해 뮤텍스와 조건변수(Condition Variable)를 사용한다 상호배제 (Mutual Exclusion) # 객체가 가지고 있는 모니터 Lock 을 통해 여러 스레드가 동시에 공유 자원에 접근하는 것을 막아 데이터의 일관성과 안전성을 보장하는 메커니즘이다 JVM 은 &amp;lsquo;synchronized&amp;rsquo; 키워드를 이용하여 뮤텍스 동기화를 암묵적으로 처리해 주고 있으며 synchronized 는 메서드나 코드 블록에 적용할 수 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/024_mutual_exclusion/</link>
      <pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/024_mutual_exclusion/</guid>
      <description>강의 메모 - Mutual Exclusion - 상호 배제 # 개요 # 뮤텍스(Mutual Exclusion) 또는 상호 배제는 공유 자원에 대한 경쟁 상태를 방지하고 동시성 제어를 위한 락 메커니즘이다 스레드가 임계영역에서 Mutex 객체의 플래그를 소유하고 있으면(락 획득) 다른 스레드가 액세스할 수 없으며 해당 임계영역에 액세스하려고 시도하는 모든 스레드는 차단되고 Mutex 객체 플래그가 해제된 경우(락 해제)에만 액세스할 수 있다 이 메커니즘은 Mutex 락을 가진 오직 한개의 스레드만이 임계영역에 진입할 수 있으며 락을 획득한 스레드만이 락을 해제 할 수 있다 결론 : 뮤텍스는 락과 락해제를 통해 자원을 보호하는 락체계 동기화 도구이다 Mutex 문제점 # 데드락(Deadlock)</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/025_semaphore/</link>
      <pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/025_semaphore/</guid>
      <description>강의 메모 - Semaphore - 세마포어 - 1,2 # 개요 # 세마포어는 공유 자원에 대한 접근을 제어하기 위해 사용되는 신호전달 메커니즘 동기화 도구이다 Mutex는 락을 획득한 쓰레드가 락을 해제 할 수 있음 세마포어 : 신호전달로, 쓰레드가 임계영역에 들어갈 수 있도록 락을 풀어주거나 하나가 아닌 여러 쓰레드가 락을 동시에 가질 수 있다. 세마포어는 정수형 변수 S 와 P(Proberen: try), V(Verhogen: increment)의 두 가지 원자적 함수로 구성된 신호전달 메커니즘 동기화 도구이다 P : 임계 영역을 사용하려는 스레드의 진입 여부를 결정하는 연산, Wait 연산이라고도 함 락을 획득하는것 V : 대기 중인 프로세스를 깨우는 신호(Wake-up)로 Signal 연산 락을 획득하고 연산한 이후, 락을 해제하는것 스레드가 임계영역에 진입하지 못할 경우 자발적으로 &amp;lsquo;대기(BLOCK)&amp;lsquo;상태에 들어가고 임계영역을 빠져나오는 스레드가 대기상태의 스레드를 실행대기상태로 깨워준다 자바에서는 java.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/020_single_multi_thread/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/020_single_multi_thread/</guid>
      <description>강의 메모 - 싱글스레드 &amp;amp; 멀티스레드 # 개요 # 프로세스는 오직 한개의 스레드로만 구성하는 싱글 스레드 프로세스와 하나 이상의 스레드로 구성하는 멀티 스레드 프로세스로 구분할 수 있다 작업 처리에 있어서 단일스레드와 멀티 스레드의 선택 기준은 어떤 방식이 자원을 더 효율적으로 사용하고 성능처리에 유리한가 하는 점이다 현대 CPU 는 대부분 멀티코어를 지원하기 때문에 병렬적 성능 및 동시적 자원 사용 관점에서는 싱글 스레드보다 멀티스레드 기반 프로그래밍이 유리한 점이 많다 싱글 스레드 혹은 아주 적은 스레드를 활용한 비동기 논블럭킹 프로그래밍은 많은 수의 멀티 스레드 기반 프로그래밍 보다 더 좋은 성능과 응답성을 보여줄 수 있다 단일스레드 # 장점 # 문맥교환이 없다 동기화 이슈가 없다 자원 비용이 적다 프로그래밍 난이도가 낮다 단점 # CPU 멀티코어 활용 못함　순차적 실행으로 응답성 및 전체 처리량이 낮다 I/O 처리 시 CPU 가 낭비된다　스레드에 오류가 발생하면 프로그램이 종료된다 멀티스레드 # 장점 # 동시성으로 사용자의 응답성 향상 CPU 멀티코어의 병렬성으로 성능 향상 CPU 낭비 없는 자원의 효율적인 사용　한 스레드 오류는 다른 스레드에 영향이 없다　단점 # 빈번한 문맥교환으로 성능이 저하 된다　스레드 간 동기화 이슈가 발생한다 스레드 생성 비용이 작지 않다 프로그래밍 난이도가 높다　멀티스레딩과 동시성 # CPU 의 동시적 작업 처리는 CPU 코어 개수보다 스레드의 개수가 많을 때 즉 , 멀티스레딩 환경에서 자원을 효율적으로 배분하고 사용하기 위해 설계된 방식이다 같은 프로그램 안에서 실행되는 여러 스레드가 읽기 및 쓰기 작업을 같은 메모리 영역에서 동시에 실행할 경우 동시성 문제가 대두된다 동시성 문제라 함은 하나의 스레드가 어떤 메모리 영역의 데이터를 쓰고 있는데 또 다른 스레드가 같은 메모리 영역의 데이터를 읽거나 쓸 경우 발생할 수 있는 문제이다 동시성 문제는 싱글스레드에서는 절대 발생하지 않으며 멀티 스레드를 운용하는 어플리케이션에서 나타나는 현상이다 a는 여러 쓰레드가 접근 가능하다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/021_synchronized_cpu/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/021_synchronized_cpu/</guid>
      <description>강의 메모 - 동기화와 CPU 관계 # 동기화 (synchronization)란&#xA;프로세스 혹은 스레드 간 공유 영역에 대한 동시접근으로 인해 발생하는 데이터 불일치(data inconsistency) 를 막고 데이터 일관성을 유지하기 위해 순차적으로 공유 영역을 수행하도록 보장하는 메카니즘이라 할 수 있다 CPU 연산 처리 이해&#xA;모든 기계어 명령(machine instruction) 은 원자성(atimicity) 을 갖는데 이는 하나의 기계어 명령어가 실행을 시작할 경우 그 명령의 수행 종료 시 까지는 인터럽트(interrupt)를 받지 않는다. 분리 불가능(indivisible) 이라고도 한다 CPU 가 두 개 이상의 명령어를 처리할 경우에은 원자성이 보장되지 않는데 이는 각 명령을 수행하는 중에 OS 가 다른 스케줄링으로 CPU 에게 다른 명령을 수행하게 함으로써 현재 수행중인 명령을 인터럽트 즉 중단하게 된다는 의미이다 두 개 이상의 명령어를 원자성으로 묶기 위해서는 스레드 간 동기화 메카니즘이 필요하다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/022_critical_section/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/022_critical_section/</guid>
      <description>강의 메모 - ThreadLocal - 1,2 # Critical Section (임계영역, 공유변수영역) # Critical Section 이란 둘 이상의 스레드가 동시에 접근해서는 안되는 공유 자원(자료 구조 또는 장치) 에 접근하는 코드 영역를 말한다. 임계영역은 entry section, critical section, exit section, remainder section 으로 구성 된다 입장영역(entry section) : critical section 에 진입하기 위해 진입허가를 요청하는 영역입니다. 임계영역(critical section) : 하나의 스레드만 접근할 수 있는 영역이다 퇴장영역(exit section) : critical section 에서 빠져나올 때 신호를 알리는 영역이다 나머지영역(remainder section) : entry section, critical section, exit section 을 제외한 나머지 영역이다 lock을 획득해야만, 임계영역에 진입 가능하다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/023_thread_safe/</link>
      <pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/023_thread_safe/</guid>
      <description>강의 메모 - ThreadLocal - 1,2 # 개요 # 여러 스레드에서 클래스나 객체에 동시에 접근해서 계속 실행하더라도 지속적인 정확성이 보장되는 코드를 스레드 세이프(thread-safe) 즉 스레드에 안전하다고 한다. 동시에 실행해도 동일한 결과값 기본적으로 클래스 명세에 스레드 안정성을 헤치는 코드나 상태를 가지고 있지 않으면 스레드에 안전하다라고 정의할 수 있다 스레드에 안전한 코드에는 경쟁상태가 없으며 경쟁 상태는 다수의 스레드가 공유 자원에 쓰기 작업을 시도할 때 발생하기 때문에 스레드가 실행될 때 어떤 자원을 공유하게 되는지 아는 것이 중요하다 스레드에 안전한 구조 # 임계영역을 동기화 한다</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/017_thread_type/</link>
      <pubDate>Sun, 14 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/017_thread_type/</guid>
      <description>강의 메모 - 사용자 스레드 vs 데몬 스레드 # 개요 # 자바에는 크게 두 가지 유형의 스레드로 구분할 수 있는데 바로 사용자 스레드(user thread)와 데몬 스레드(daemon thread)이다. 사용자 스레드는 사용자 스레드를 낳고 데몬 스레드는 데몬 스레드를 낳는다.즉 자식 스레드는 부모 스레드의 상태를 상속 받는다 자바 어플리케이션이 실행이 되면 JVM 은 사용자 스레드인 메인스레드와 나머지 데몬 스레드를 동시에 생성하고 시작한다 main thread # 메인 스레드는 어플리케이션에서 가장 중요한 부분으로서 어플리케이션을 실행할 때마다 메인 스레드가 생성되어 실행된다 메인 스레드는 어플리케이션을 실행하는 최초의 스레드이자 어플리케이션 실행을 완료하는 마지막 스레드의 역할을 한다 메인 스레드에서 여러 하위 스레드를 추가로 시작할 수 있고 하위 스레드는 또 여러 하위 스레드를 시작할 수 있다 메인 스레드가 사용자 스레드이기 때문에 하위 스레드는 모두 사용자 스레드가 된다 user thread (사용자 스레드) # 사용자 스레드는 메인 스레드에서 직접 생성한 스레드를 의미한다 사용자 스레드는 각각 독립적인 생명주기를 가지고 실행하게 되며 메인 스레드를 포함한 모든 사용자 스레드가 종료하게 되면 어플리케이션이 종료하게 된다 사용자 스레드는 foreground 에서 실행되는 높은 우선순위를 가지며 JVM은 사용자 스레드가 스스로 종료될 때까지 어플리케이션을 강제로 종료하지 않고 기다린다 자바가 제공하는 스레드 풀인 ThreadPoolExecutor 은 사용자 스레드를 생성한다 daemon thread (데몬 스레드) # 데몬 스레드는 JVM 에서 생성한 스레드이거나 직접 데몬 스레드로 생성한 경우를 말한다 모든 사용자 스레드가 작업을 완료하면 데몬 스레드의 실행 여부에 관계없이 JVM 이 데몬 스레드를 강제로 종료하고 어플리케이션이 종료한다 데몬 스레드의 생명주기는 사용자 스레드에 따라 다르며 낮은 우선순위를 가지고 background 에서 실행된다 데몬 스레드는 사용자 스레드를 보조 및 지원하는 성격을 가진 스레드로서 보통 사용자 작업을 방해하지 않으면서 백그라운드에서 자동으로 작동되는 기능을 가진 스레드이다 자바가 제공하는 스레드 풀인 ForkJoinPool 은 데몬 스레드를 생성한다 데몬 스레드 생성 # void setDaemon(boolean on) 스레드를 데몬 또는 비데몬 스레드로 표시하며 이 메소드는 반드시 스레드가 시작되기 전에 호출되어야 한다 스레드가 실행 중인 동안 setDaemon()을 호출하려고 하면 IllegalThreadStateException 이 발생한다 true 이면 데몬스레드가 되며 false 이면 사용자 스레드가 된다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/018_thread_group/</link>
      <pubDate>Sun, 14 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/018_thread_group/</guid>
      <description>강의 메모 - ThreadGroup # 개요 # 자바는 스레드 그룹(ThreadGroup)이라는 객체를 통해서 여러 스레드를 그룹화하는 편리한 방법을 제공한다 ThreadGroup은 스레드 집합을 나타내며 스레드 그룹에는 다른 스레드 그룹도 포함될 수 있고 그룹 내의 모든 스레드는 한 번에 종료하거나 중단할 수 있다 스레드는 반드시 하나의 스레드 그룹에 포함되어야 하며 명시적으로 스레드 그룹에 포함시키지 않으면 자신을 생성한 스레드가 속해 있는 스레드 그룹에 포함되어 진다 일반적으로 사용자가 main 스레드에서 생성하는 모든 스레드는 기본적으로 main 스레드 그룹에 속하게 된다 코드로 별도 스레드를 만들면 기본적으로 main 스레드 그룹에 속해진다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/019_threadLocal/</link>
      <pubDate>Sun, 14 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/019_threadLocal/</guid>
      <description>강의 메모 - ThreadLocal - 1,2 # 개요 # 자바에서 스레드는 오직 자신만이 접근해서 읽고 쓸수 있는 로컬 변수 저장소를 제공하는데 이를 ThreadLocal 이라고 한다 각 스레드는 고유한 ThreadLocal 객체를 속성으로 가지고 있으며 ThreadLocal 은 스레드 간 격리되어 있다 스레드는 ThreadLocal 에 저장된 값을 특정한 위치나 시점에 상관없이 어디에서나 전역변수처럼 접근해서 사용할 수 있다. 변수 값을 전달하지 않아도 된다 모든 스레드가 공통적으로 처리해야 하는 기능이나 객체를 제어해야 하는 상황에서 스레드마다 다른 값을 적용해야 하는 경우 사용한다 (인증 주체 보관, 트랜잭션 전파, 로그 추적기 등) Thread 마다 ThreadLocal을 가지고있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/012_thread_interrupt/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/012_thread_interrupt/</guid>
      <description>강의 메모 - interrupt() # 개요 # Interrupt 의 사전적 의미는 ‘방해하다’ 라는 뜻으로 어떤 주체의 행동이나 실행흐름을 방해한다는 의미로 해석 할 수 있다 자바 스레드에서 interrupt() 는 특정한 스레드에게 인터럽트 신호를 알려 줌으로써 스레드의 실행을 중단하거나, 작업 취소, 강제 종료 등으로 사용할 수 있다 interrupt() # interrupt() 는 스레드에게 인터럽트가 발생했다는 신호를 보내는 메카니즘이다 interrupt() 는 스레드가 현재 실행 흐름을 멈추고 인터럽트 이벤트를 먼저 처리하도록 시그널을 보내는 장치라 할 수 있다 interrupted 속성 스레드는 인터럽트 상태(Interrupt State )로 알려진 interrupted 를 가지고 있으며 인터럽트 발생 여부를 확인할 수 있는 상태 값이다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/013_thread_info/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/013_thread_info/</guid>
      <description>강의 메모 - name() / currentThread() / isAlive() # Thread Name # 멀티 스레드 환경에서 어떤 스레드가 실행 중인지 알아야 할 경우 스레드에 사용자 이름을 지정하면 실행 중인 스레드를 쉽게 찾을 수 있다 디버깅할 때 어떤 스레드가 무슨 작업을 하고 있는지 정확하게 파악하기 위해서 스레드 이름을 정하는 것이 큰 도움이 된다 자바에서 스레드가 생성되면 스레드 이름이 자동으로 주어진다. 이건 사용자가 정하는 것이 아니다 가장 먼저 생성되는 메인 스레드의 이름은 main 이다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/014_thread_priority/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/014_thread_priority/</guid>
      <description>강의 메모 - Priority # 스레드 우선순위 (Priority) # 단일 CPU에서 여러 스레드를 실행하는 것을 스케줄링이라고 하며 스레드는 스케줄링에 의해 선점되어 CPU 를 할당받는다&#xA;자바 런타임은 고정 우선순위 선점형 스케줄링(fixed-priority pre-emptive scheduling ) 으로 알려진 매우 단순하고 결정적인 스케줄링 알고리즘을 지원한다&#xA;이 알고리즘은 실행 대기 상태의 스레드 중에 상대적인 우선 순위에 따라 스레드를 예약한다&#xA;우선순위 개념&#xA;Java에서 스레드의 우선 순위는 1에서 10 사이의 정수이며 정수 값이 높을수록 우선순위가 높다 스레드가 생성될 때 우선순위 값이 정해지며 기본 우선 순위인 5 로 설정된다 스케줄러는 우선순위가 높은 스레드를 실행하다가 해당 스레드가 중지, 양보 또는 실행 불가능이 되는 경우 우선 순위가 낮은 스레드를 실행하기 시작한다 두 스레드의 우선순위가 같을 경우 라운드 로빈(순환 할당) 스케줄링 방식에 의해 다음 스레드를 선택한다 스케줄러가 반드시 우선순위가 높은 스레드를 실행한다고 보장 할 수 없다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/015_thread_uncaughtExceptionHandler/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/015_thread_uncaughtExceptionHandler/</guid>
      <description>강의 메모 - 스레드 예외처리 - UncaughtExceptionHandler # 개요 # 기본적으로 스레드의 run() 은 예외를 던질 수 없기 때문에 예외가 발생할 경우 run() 안에서만 예외를 처리해야 한다 RuntimeException 타입의 예외가 발생할 지라도 스레드 밖에서 예외를 캐치할 수 없고 사라진다 스레드가 비정상적으로 종료되었거나 특정한 예외를 스레드 외부에서 캐치하기 위해서 자바에서는 UncaughtExceptionHandler 인터페이스를 제공한다 UncaughtExceptionHandler # 캐치 되지 않는 예외에 의해 Thread가 갑자기 종료했을 때에 호출되는 핸들러 인터페이스 어떤 원인으로 인해 스레드가 종료되었는지 대상 스레드와 예외를 파악할 수 있다 예외가 발생하면 uncaughtException 이 호출되고 대상 스레드 t 와 예외 e 가 인자로 전달된다 Thread API # static void setDefaultUncaughtExceptionHandler</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/016_thread_stop_flag/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/016_thread_stop_flag/</guid>
      <description>강의 메모 - 스레드 중지 – flag variable vs interrupt() - 1,2 # 개요 # 자바에서는 무한 반복이나 지속적인 실행 중에 있는 스레드를 중지하거나 종료할 수 있는 API 를 더 이상 사용할 수 없다 (suspend(), stop()) 수행 중에 강제로 종료해버리면 이슈가 생길 수 있기 때문 스레드를 종료하는 방법은 플래그 변수를 사용하거나 interrupt() 를 활용해서 구현할 수 있다 Flag Variable # 플래그 변수의 값이 어떤 조건에 만족할 경우 스레드의 실행을 중지하는 방식 플래그 변수는 동시성 문제로 가능한 atomic 변수나 volatile 키워드를 사용하도록 한다 동시성 문제 때문 running 변수는 여러 쓰레드가 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/011_thread_join/</link>
      <pubDate>Mon, 08 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/011_thread_join/</guid>
      <description>강의 메모 - join() # 개요 # join() 메서드는 한 스레드가 다른 스레드가 종료될 때까지 실행을 중지하고 대기상태에 들어갔다가 스레드가 종료되면 실행대기 상태로 전환된다 T1, T2가 있을때, T1이 T2의 모든 작업이 종료될때까지 대기했다가, T2의 작업이 다 끝나고나서 T1이 본인의 작업을 이어서 나가야할 경우 T1 기준으로 T2.join()을 수행 대기는 T1이 하는것 스레드의 순서를 제어하거나 다른 스레드의 작업을 기다려야 하거나 순차적인 흐름을 구성하고자 할 때 사용할 수 있다 Object 클래스의 wait() 네이티브 메서드로 연결되며 시스템 콜을 통해 커널모드로 수행한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/010_thread_sleep/</link>
      <pubDate>Sun, 07 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/010_thread_sleep/</guid>
      <description>강의 메모 - sleep() # 개요 # 지정된 시간 동안 현재 스레드의 실행을 일시 정지하고 대기상태로 빠졌다가 시간이 지나면 실행대기 상태로 전환된다 native 메서드로 연결되며 시스템 콜을 통해 커널모드에서 수행 후 유저모드로 전환한다 이 간단한 메서드 자체도 jvm 자체에서 실행되지 못하고 커널모드에서 수행된다. 컨텍스트 스위칭 발생 API 및 예외 # staic sleep(long millis) throws InterruptedException # 지정한 밀리초 시간 동안 스레드를 수면 상태로 만든다 밀리초에 대한 인수 값은 음수가 될 수 없으며 음수 일 경우 IllegalArgumentException 이 발생한다</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/009_thread_status/</link>
      <pubDate>Thu, 04 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/009_thread_status/</guid>
      <description>강의 메모 - 스레드 생명주기와 상태 # 개요 # 자바 스레드는 생성, 실행, 종료에 따른 상태를 가지고있다. OS 스레드 상태를 의미하지 않는다. 자바 스레드는 어떤 시점이던 6가지 상태 중 오직 1개의 상태를 가질 수 있다. 자바 스레드의 현재 상태를 가져오려면 Thread의 getState() 메서드를 사용하여 가져올 수 있다. Thread 클래스에는 스레드 상태에 대한 ENUM 상수를 정의하는 Thread.State 클래스를 제공한다. 스레드 상태 # NEW : 객체만 생성된 상태 RUNNABLE WAITING : 대기는 언제하는가?</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/008_thread_start/</link>
      <pubDate>Wed, 03 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/008_thread_start/</guid>
      <description>강의 메모 - 스레드 실행 및 종료 # 개요 # 자바 스레드는 OS 스케줄러에 의해 실행 순서가 결정되며, 스레드 실행 시점을 JVM에서 제어할 수 없다. kernel이 제어한다. 새로운 스레드는 현재 스레드와 독립적으로 실행되고, 최대 한번 시작할 수 있고, 스레드가 종료된 이후에는 다시 시작할 수 없다.&#xA;스레드 실행 # start() : 스레드를 실행시키는 메서드로 시스템 콜을 통해서 커널에 커널 스레드 생성을 요청한다.&#xA;start() 호출 후 System Call -&amp;gt; (execute) -&amp;gt; Kernel -&amp;gt; (create) -&amp;gt; Kernel Thread 순서</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/004_cpu_bound_io_bound/</link>
      <pubDate>Tue, 02 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/004_cpu_bound_io_bound/</guid>
      <description>강의 메모 - CPU Bound &amp;amp; I/O Bound # 개요 # 프로세스는 CPU 작업과 I/O 작업의 연속된 흐름으로 진행된다.&#xA;CPU 작업 # I/O 작업 # 파일을 읽는 행위 등 CPU는 실제 데이터를 읽어들이는 일을 하진 않고, 이를 다른 디바이스에 맡긴다. CPU는 다시금 연산작업을 할 수 있는 쓰레드를 할당받고, CPU는 그 쓰레드에게 실제 연산작업을 시킨다. I/O 작업이 일어날 경우, CPU는 다른 쓰레드를 선택하는거고, 해당 I/O 작업을 하고있는 쓰레드는 I/O 작업이 끝날때까지 기다려야한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/005_user_kernel_systemcall/</link>
      <pubDate>Tue, 02 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/005_user_kernel_systemcall/</guid>
      <description>강의 메모 - 사용자 모드 &amp;amp; 커널 모드 # 개요 # 운영체제 : 컴퓨터 시스템의 자원을 효율적으로 관리하는 소프트웨어 운영체제의 여러 기능 중 핵심 기능을 담당하는 부분을 커널(kernel) 이라고 한다.&#xA;사용자가 운영체제 위에서 실행되는 프로그램을 편하고 효율적으로 사용할 수 있게 하드웨어와 소프트웨어 간 중개자 역할을 한다. CPU, I/O 장치, 메모리, 저장소와 같은 하드웨어 자원을 프로그램에 잘 할당하는 데 있다. 운영체제는 응용 프로그램이 하드웨어 자원에 직접 접근하는 것을 방지하여 자원을 보호한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/006_user_mode_kernel_mode_thread/</link>
      <pubDate>Tue, 02 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/006_user_mode_kernel_mode_thread/</guid>
      <description>강의 메모 - 사용자 수준 스레드 &amp;amp; 커널 수준 스레드 # 개요 # 스레드는 사용자 수준 스레드(User Level Thread), 커널 수준 스레드(Kernel Level Thread) 로 구분된다. 사용자 수준 스레드 : 사용자 프로그램에서 관리하는 스레드 커널 수준 스레드 : OS에서 관리하는 스레드 ** CPU의 할당 단위는 쓰레드다. **&#xA;사용자 수준 스레드(User Level Thread) # 스레드 라이브러리(Pthreads, WIndows Threads, Java Threads(JVM))에 의해 스레드의 생성, 종료, 스레드간 메시지 전달, 스케줄링 스레드 보관 등 모든 것을 관리한다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/007_java_thread/</link>
      <pubDate>Tue, 02 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/007_java_thread/</guid>
      <description>강의 메모 - Java Thread Fundamentals &amp;gt; 스레드 생성 # 개요 # 자바 스레드는 JVM에서 User Thread를 생성할때 시스템 콜을 통해서 커널에 생성된 Kernel Thread와 1:1 매핑이 되어 최종적으로 커널에서 관리된다. JVM에서 스레드를 생성할때마다 커널에서 자바 스레드와 대응하는 커널 스레드를 생성한다. 자바에서 Platform Thread으로 정의되어 있다. 즉, OS 플랫폼에 따라 JVM이 사용자 스레드를 매핑하게 된다. Platform Thread : 운영체제에서 스케줄링되는 Kernel 쓰레드와 1:1 매핑된 플랫폼 쓰레드의 생성을 지원한다. 사용자 수준 쓰레드처럼 쓰레드 관리, 스케줄링 등을 하지않고, 생성만 하고 커널 쓰레드와 매핑만 되어있음 (커널의 제어를 받는다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/003_context_switching/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/003_context_switching/</guid>
      <description>강의 메모 - ContextSwitching # 개요 # 하나의 CPU는 동일한 시간에 1개의 task만 수행 가능, 여러 프로세스를 동시에 실행X 하나의 CPU에서 여러 프로세스를 동시성으로 처리하기 위해서는 한 프로세스에서 다른 프로세스로 전환해야하는데, 이것을 컨텍스트 스위칭이라고 한다.&#xA;Context # 프로세스 간 전환을 위해서는 이전에 어디까지 명령을 수행했고, CPU Register에는 어떤 값이 저장되어있는지에 대한 정보가 필요하다. Context는 CPU가 해당 프로세스를 실행하기 위한 프로세스의 정보를 의미하며, 이 정보들은 운영체제가 관리하는 PCB라고 하는 자료구조의 공간에 저장된다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/001_process_thread/</link>
      <pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/001_process_thread/</guid>
      <description>강의 메모 - Process &amp;amp; Thread # Process # File down -&amp;gt; .exe 파일 실행 -&amp;gt; 설치된 상태 : 프로그램 (!= 프로세스) 프로세스는 프로그램의 실제 실행. =&amp;gt; 프로그램 데이터들이 메모리에 올라와 CPU를 할당받고 명령을 수행하고있는 상태&#xA;각각의 프로세스는 RAM(메모리)의 각각의 영역을 할당받음&#xA;4GB 정도 할당 받는다고 해보자.&#xA;1GB 정도는 운영체제를 위한 커널(Kernel) 서비스를 위해 차지한다. 나머지 3GB가 Stack, heap, data, code 등 영역을 차지한다. 프로세스는 자식 프로세스를 가질 수 있다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/parallel_programming/002_parallel_concurrent/</link>
      <pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/parallel_programming/002_parallel_concurrent/</guid>
      <description>강의 메모 - Parallel &amp;amp; Concurrent # 동시성 # 특정한 순서 없이 겹치는 기간에 시작, 실행 및 완료되는 여러 작업에 관한것 ex) 사람이 있다. 작업1, 작업2가 있다. 이 사람은 작업1, 작업2를 모두 해야한다. 작업1을 하고 작업2를 하는데, 시간적으로 동시에하는건 아니고 계속 번갈아가면서 한다. 이게 짧은 찰나로 번갈아가면서 하기 때문에 동시에 하는것처럼 보인다. (순차적이지 않다. 순서가 없다.) (시간적인 동시성이 아님)&#xA;작업의 갯수 &amp;gt; CPU 갯수 Thread1, Thread2가 번갈아가면서 Task를 수행 빠른게 목적이 아닌, CPU의 효율적인 사용이 목적이다.</description>
    </item>
    <item>
      <title></title>
      <link>https://example.com/docs/java/001_facade_pattern/</link>
      <pubDate>Wed, 13 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/docs/java/001_facade_pattern/</guid>
      <description>퍼사드 (Facade) 패턴 # 복잡한 서브 시스템 의존성을 최소화하는 방법. 클라이언트가 사용해야 하는 복잡한 서브 시스템 의존성을 간단한 인터페이스로 추상화 할 수 있다. 복잡한 디테일을 퍼사드 뒤로 숨긴다. 복잡한 서브 클래스들의 공통적인 기능을 정의하는 상위 수준의 인터페이스를 제공하는 패턴이다. 서브 클래스의 코드에 의존하는 일을 감소시켜 주고, 복잡한 소프트웨어를 간단히 사용 할 수 있게 간단한 인터페이스를 제공해준다. 서브 시스템(SubSystem)들 간의 종속성을 줄여줄 수 있으며, 퍼사드 객체를 사용하는 곳(Client)에서는 여러 서브 클래스들을 호출할 필요 없이 편리하게 사용할 수 있다.</description>
    </item>
  </channel>
</rss>
